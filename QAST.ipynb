{"cells":[{"cell_type":"markdown","metadata":{"id":"yf_6Ceq0Iihz"},"source":["# Setup"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"Q-JenvwhoMix","executionInfo":{"status":"ok","timestamp":1686573796357,"user_tz":-120,"elapsed":3,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["import os\n","os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\""]},{"cell_type":"code","execution_count":4,"metadata":{"id":"R-zcpoSpGGkH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686573817947,"user_tz":-120,"elapsed":21592,"user":{"displayName":"Bota D","userId":"04482539542256056244"}},"outputId":"141b9614-4606-4eed-e688-2b1bdb1d521b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ppFPaRtjzp6Q","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686573817948,"user_tz":-120,"elapsed":3,"user":{"displayName":"Bota D","userId":"04482539542256056244"}},"outputId":"be61aa17-1604-41ab-9304-59df44b7060e"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Thesis\n"]}],"source":["%cd /content/drive/MyDrive/Thesis/"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"ECdJF5wYTFp2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686573832028,"user_tz":-120,"elapsed":14083,"user":{"displayName":"Bota D","userId":"04482539542256056244"}},"outputId":"7f7c0ec5-451d-4ac7-afea-ce3d0f8d8cc6"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q -r requirements.txt"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"p_LnIPQ7HY05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686573832028,"user_tz":-120,"elapsed":4,"user":{"displayName":"Bota D","userId":"04482539542256056244"}},"outputId":"55624e64-2698-43cf-a41b-1a835989c6c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Thesis/ast\n"]}],"source":["%cd /content/drive/MyDrive/Thesis/ast"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"ohmUr6vy_iut","executionInfo":{"status":"ok","timestamp":1686573832455,"user_tz":-120,"elapsed":430,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n","%matplotlib inline\n","%reload_ext autoreload\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"e6FXw8WeHCwy","executionInfo":{"status":"ok","timestamp":1686573844635,"user_tz":-120,"elapsed":12181,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import torch.nn as nn\n","from torch.cuda.amp import autocast\n","from einops.layers.torch import Rearrange\n","\n","from src import dataloader\n","from src import models\n","from src.traintest import train, validate\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"btoms-hdG5o2","executionInfo":{"status":"ok","timestamp":1686573844635,"user_tz":-120,"elapsed":2,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["class Arguments():\n","\n","  model='ast'\n","  dataset='speechcommands'\n","  imagenetpretrain=True\n","  audiosetpretrain=False\n","\n","  bal=None\n","  lr=2.5e-4\n","\n","  n_epochs=20\n","  freqm=48\n","  timem=48\n","  mixup=0.6\n","  batch_size=128\n","  fstride=10\n","  tstride=10\n","  dataset_mean=-6.845978\n","  dataset_std=5.5654526\n","  audio_length=128\n","  noise=True\n","\n","  num_workers = 32\n","  exp_dir = '/content/drive/MyDrive/Thesis/resout_not_pretrained'\n","  optimizer = 'adam'\n","  metrics='acc'\n","  loss='BCE'              \n","\n","  lrscheduler_start=5\n","  lrscheduler_step=1\n","  lrscheduler_decay=0.85\n","\n","  warmup = False\n","  wa = False\n","  wa_start = 1\n","  wa_end = 5\n","\n","  n_print_steps = 100\n","  n_class = 35\n","  lr_patience = 2\n","  save_model = True\n","args = Arguments()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"X2tq4j0_nkIb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686573844636,"user_tz":-120,"elapsed":3,"user":{"displayName":"Bota D","userId":"04482539542256056244"}},"outputId":"003cc20a-e9b5-4ac5-9754-3dcae82ab433"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Thesis/Quaternion_Transformer_Pytorch\n"]}],"source":["%cd /content/drive/MyDrive/Thesis/Quaternion_Transformer_Pytorch/"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"c-EZhAS1nXtY","executionInfo":{"status":"ok","timestamp":1686573847305,"user_tz":-120,"elapsed":2671,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["from core_qnn.quaternion_ops import *\n","from core_qnn.quaternion_layers import *\n","from timm.models.layers import to_2tuple,trunc_normal_"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"7AZjzRXVUP_S","executionInfo":{"status":"ok","timestamp":1686573847305,"user_tz":-120,"elapsed":4,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"YUzSKblrz0kQ"},"source":["# Transformer part"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"P7KNFCd_WQ5_","executionInfo":{"status":"ok","timestamp":1686573847305,"user_tz":-120,"elapsed":4,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["def QNorm(x, eps):\n","    r, i, j, k = torch.chunk(x, chunks=4, dim=-1)\n","    qnorm = torch.sqrt(r * r + i * i + j * j + k * k + eps)\n","    r = r / qnorm\n","    i = i / qnorm\n","    j = j / qnorm\n","    k = k / qnorm\n","\n","    return [r, i, j, k]\n","\n","\n","class Norm(nn.Module):\n","    def __init__(self, d_model, eps=1e-6):\n","        super().__init__()\n","\n","        self.size = d_model // 4\n","        # create two learnable parameters to calibrate normalisation\n","        self.alpha = nn.Parameter(torch.ones(self.size))\n","        self.bias = nn.Parameter(torch.zeros(self.size))\n","        self.eps = eps\n","\n","    def forward(self, x):\n","        [r, i, j, k] = QNorm(x, self.eps)\n","\n","        norm_r = self.alpha * r + self.bias\n","        norm_i = self.alpha * i + self.bias\n","        norm_j = self.alpha * j + self.bias\n","        norm_k = self.alpha * k + self.bias\n","        norm = torch.cat([norm_r, norm_i, norm_j, norm_k], dim=-1)\n","\n","        return norm"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"yUtAPPt2bN9f","executionInfo":{"status":"ok","timestamp":1686573847305,"user_tz":-120,"elapsed":3,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["def quarternion_multiplication(a, b, transpose=True):\n","    \"\"\" Performs hamilton product between two quarternion sequences.\n","    a = (r,x,y,z)\n","    b = (r',x',y',z')\n","    following:\n","    (rr' - xx' - yy' - zz')  +\n","    (rx' + xr' + yz' - zy')i +\n","    (ry' - xz' + yr' + zx')j +\n","    (rz' + xy' - yx' + zr')k\n","    \"\"\"\n","\n","\n","    ar, ax, ay, az = torch.chunk(a, chunks=4, dim=-1)\n","    br, bx, by, bz = torch.chunk(b, chunks=4, dim=-1)\n","    #print(ar.shape)\n","    #print(br.shape)\n","\n","    if transpose==True:\n","        if len(br.shape)>2:\n","        \n","            r = torch.matmul(ar,br.transpose(-2,-1)) - torch.matmul(ax,bx.transpose(-2,-1)) - torch.matmul(ay,by.transpose(-2,-1)) - torch.matmul(az,bz.transpose(-2,-1))\n","            i = torch.matmul(ar,bx.transpose(-2,-1)) + torch.matmul(ax,br.transpose(-2,-1)) + torch.matmul(ay,bz.transpose(-2,-1)) - torch.matmul(az,by.transpose(-2,-1))\n","            j = torch.matmul(ar,by.transpose(-2,-1)) - torch.matmul(ax,bz.transpose(-2,-1)) + torch.matmul(ay,br.transpose(-2,-1)) + torch.matmul(az,bx.transpose(-2,-1))\n","            k = torch.matmul(ar,bz.transpose(-2,-1)) + torch.matmul(ax,by.transpose(-2,-1)) - torch.matmul(ay,bx.transpose(-2,-1)) + torch.matmul(az,br.transpose(-2,-1))\n","            \n","        else:\n","            r = torch.matmul(ar, br.t()) - torch.matmul(ax, bx.t()) - torch.matmul(ay, by.t()) - torch.matmul(az, bz.t())\n","            i = torch.matmul(ar, bx.t()) + torch.matmul(ax, br.t()) + torch.matmul(ay, bz.t()) - torch.matmul(az, by.t())\n","            j = torch.matmul(ar, by.t()) - torch.matmul(ax, bz.t()) + torch.matmul(ay, br.t()) + torch.matmul(az, bx.t())\n","            k = torch.matmul(ar, bz.t()) + torch.matmul(ax, by.t()) - torch.matmul(ay, bx.t()) + torch.matmul(az, br.t())\n","    else:\n","        r = torch.matmul(ar,br) - torch.matmul(ax,bx) - torch.matmul(ay,by) - torch.matmul(az,bz)\n","        i = torch.matmul(ar,bx) + torch.matmul(ax,br) + torch.matmul(ay,bz) - torch.matmul(az,by)\n","        j = torch.matmul(ar,by) - torch.matmul(ax,bz) + torch.matmul(ay,br) + torch.matmul(az,bx)\n","        k = torch.matmul(ar,bz) + torch.matmul(ax,by) - torch.matmul(ay,bx) + torch.matmul(az,br)\n","      \n","    return torch.cat([r, i, j, k], dim=-1)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"3mfr1oHAlC3K","executionInfo":{"status":"ok","timestamp":1686573847305,"user_tz":-120,"elapsed":3,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["def ComponentActivation(q, act_func=F.gelu):\n","    scores_r, scores_i, scores_j, scores_k  = torch.chunk(q, 4, dim=-1)\n","    if act_func == F.softmax:\n","      scores_r = act_func(scores_r, dim = -1)\n","      scores_i = act_func(scores_i, dim = -1)\n","      scores_j = act_func(scores_j, dim = -1)\n","      scores_k = act_func(scores_k, dim = -1)\n","    else:\n","      scores_r = act_func(scores_r)\n","      scores_i = act_func(scores_i)\n","      scores_j = act_func(scores_j)\n","      scores_k = act_func(scores_k)\n","\n","\n","    scores = torch.cat([scores_r, scores_i, scores_j, scores_k], dim=-1)\n","    return scores\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"z1HM7UBxa6Lm","executionInfo":{"status":"ok","timestamp":1686573847306,"user_tz":-120,"elapsed":4,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["#TODO not sure about scale applied to q only\n","class Attention(nn.Module):\n","\n","    def __init__(\n","            self,\n","            dim, #embed_size\n","            num_heads=8,\n","            qkv_bias=False,\n","            qk_norm=False,\n","            attn_drop=0.,\n","            proj_drop=0.,\n","            norm_layer=nn.LayerNorm,\n","    ):\n","        super().__init__()\n","        assert dim % num_heads == 0, 'dim should be divisible by num_heads'\n","        self.num_heads = num_heads\n","        self.head_dim = dim // num_heads\n","        self.scale = self.head_dim ** -0.5\n","\n","        self.qkv = QuaternionLinearAutograd(dim, dim * 3, bias=qkv_bias)\n","        self.q_norm = Norm(self.head_dim) if qk_norm else nn.Identity()\n","        self.k_norm = Norm(self.head_dim) if qk_norm else nn.Identity()\n","        self.attn_drop = nn.Dropout(attn_drop)\n","        self.proj = QuaternionLinearAutograd(dim, dim)\n","        self.proj_drop = nn.Dropout(proj_drop)\n","\n","    def forward(self, x):\n","\n","        B, N, C = x.shape\n","        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, self.head_dim).permute(2, 0, 3, 1, 4)\n","        q, k, v = qkv.unbind(0)\n","        q, k = self.q_norm(q), self.k_norm(k)\n","\n","        \n","        q = q * self.scale\n","   \n","        attn = quarternion_multiplication(q,k)\n","        # print(\"Att shape\", attn.shape)\n","\n","        # attn = q @ k.transpose(-2, -1)\n","        # attn = attn.softmax(dim=-1)\n","        \n","        attn =  ComponentActivation(attn, act_func=F.softmax)\n","        attn = self.attn_drop(attn)\n","\n","        x = quarternion_multiplication(attn,v, transpose = False)\n","\n","        # print(\"x shape att v\", x.shape)\n","        x = x.transpose(1, 2).reshape(B, N, C)\n","        # print(\"x shape after transpose and reshape\", x.shape)\n","\n","        x = self.proj(x)\n","        # print(\"x shape after lin\", x.shape)\n","        x = self.proj_drop(x)\n","        return x"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"7MtSK3lLq4PJ","executionInfo":{"status":"ok","timestamp":1686573847306,"user_tz":-120,"elapsed":4,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["class Mlp(nn.Module):\n","\n","    \"\"\" MLP as used in Vision Transformer, MLP-Mixer and related networks\n","    \"\"\"\n","    def __init__(self, in_features, hidden_features=None, out_features=None, drop=0.):\n","        super().__init__()\n","        out_features = out_features or in_features\n","        hidden_features = hidden_features or in_features\n","        # drop_probs = to_2tuple(drop)\n","\n","        self.fc1 = QuaternionLinearAutograd(in_features, hidden_features)\n","        # self.act = act_layer()\n","        self.drop1 = nn.Dropout(drop)\n","        self.fc2 = QuaternionLinearAutograd(hidden_features, out_features)\n","        self.drop2 = nn.Dropout(drop)\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = ComponentActivation(x, act_func=F.gelu)\n","        # x = self.act(x)\n","        x = self.drop1(x)\n","        x = self.fc2(x)\n","        x = self.drop2(x)\n","        return x"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"Bi3_WZpLebP7","executionInfo":{"status":"ok","timestamp":1686573847306,"user_tz":-120,"elapsed":4,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["class Block(nn.Module):\n","\n","    def __init__(\n","            self,\n","            dim,\n","            num_heads,\n","            mlp_ratio=4.,\n","            qkv_bias=False,\n","            qk_norm=False,\n","            drop=0.,\n","            attn_drop=0.,\n","            init_values=None,\n","            drop_path=0.,\n","            act_layer=nn.GELU,\n","            norm_layer=Norm\n","    ):\n","        super().__init__()\n","        self.norm1 = norm_layer(dim)\n","        self.attn = Attention(\n","            dim,\n","            num_heads=num_heads,\n","            qkv_bias=qkv_bias,\n","            qk_norm=qk_norm,\n","            attn_drop=attn_drop,\n","            proj_drop=drop,\n","            norm_layer=norm_layer,\n","        )\n","        # self.ls1 = LayerScale(dim, init_values=init_values) if init_values else nn.Identity()\n","        # self.drop_path1 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n","\n","        self.norm2 = norm_layer(dim)\n","        self.mlp = Mlp(\n","            in_features=dim,\n","            hidden_features=int(dim * mlp_ratio),\n","            # act_layer=act_layer,\n","            drop=drop,\n","        )\n","        # self.ls2 = LayerScale(dim, init_values=init_values) if init_values else nn.Identity()\n","        # self.drop_path2 = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n","\n","    def forward(self, x):\n","        # x = x + self.drop_path1(self.ls1(self.attn(self.norm1(x))))\n","        # x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))\n","        x = x + self.attn(self.norm1(x))\n","        x = x + self.mlp(self.norm2(x))\n","        return x"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"ik4AS-H_sNpu","executionInfo":{"status":"ok","timestamp":1686573847306,"user_tz":-120,"elapsed":4,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ClelqeV6Im8F"},"source":["# QModel"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"iPoMpj0JRq2A","executionInfo":{"status":"ok","timestamp":1686573892577,"user_tz":-120,"elapsed":372,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["# # Patchinfy using Rearrange (cut w/out CNN) returns quaternions and Qproj\n","# class PatchifierEmbed(nn.Module):\n","#     def __init__(self, patch_size=16, embedding_dim = 768):\n","#         super().__init__()\n","#         # [B, H, W] with C = 1 omited ([B ,C, H, W])\n","#         # [B, Number_of_patches, Patch_size=patch_size*patch_size] \n","#         # for Q version [B, Number_of_patches, 4*Patch_size=4*patch_size*patch_size] \n","#         self.patchifier = Rearrange('b (h p1) (w p2) -> b (h w) (p1 p2)', p1=patch_size, p2=patch_size)\n","#         # self.proj = nn.Linear(patch_size*patch_size*n_channels, embedding_dim)\n","#         self.Qproj = QuaternionLinearAutograd(\n","#             patch_size*patch_size*4, embedding_dim\n","#         )\n","\n","#     def forward(self, x):\n","#         _, n_channels, _, _ = x.shape\n","#         y = []\n","#         for channel in range(n_channels):\n","#           y.append(self.patchifier(x[:, channel,:,:]))\n","#         zeros = torch.zeros(y[0].shape).to(device)\n","#         if n_channels==1:\n","#           # grey => r\n","#           # zero/black => i,j,k \n","#           out = torch.cat((y[0], zeros, zeros, zeros), 2)\n","#         else:\n","#           # zero => r\n","#           # r,g,b => i,j,k \n","#           out = torch.cat((zeros, y[0], y[1], y[2]), 2)\n","#         out = self.Qproj(out)\n","#         return out\n","\n","# Patch using convensional CNN as in original paper\n","# override the timm package to relax the input shape constraint.\n","# \n","class PatchEmbed(nn.Module):\n","    def __init__(self, img_size=256, patch_size=16, stride = 10, in_chans=4, embed_dim=768):\n","        super().__init__()\n","\n","        img_size = to_2tuple(img_size)\n","        patch_size = to_2tuple(patch_size)\n","        # num_patches = (img_size[1] // patch_size[1]) * (img_size[0] // patch_size[0])\n","        self.img_size = img_size\n","        self.patch_size = patch_size\n","        # self.num_patches = num_patches\n","\n","\n","        # TODO compare qconv or conv works for patchembedding \n","        # self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)\n","        self.projq = QuaternionConv(in_chans, embed_dim, patch_size, stride)\n","\n","    def forward(self, x):\n","        zeros = torch.zeros(x.shape).to(device)\n","        x = torch.cat((zeros, x, x, x), 1)\n","        # print(\"Qx shape: [0, g, g, g]\", x.shape)\n","        x = self.projq(x).flatten(2).transpose(1, 2)\n","        return x"]},{"cell_type":"code","execution_count":28,"metadata":{"id":"2k-hhODdHsGO","executionInfo":{"status":"ok","timestamp":1686573894848,"user_tz":-120,"elapsed":315,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["class ASTModel(nn.Module):\n","  def __init__(self, label_dim=527, fstride=10, tstride=10, input_fdim=128, input_tdim=1024, imagenet_pretrain=True, audioset_pretrain=False, model_size='base384', verbose=True):\n","    super(ASTModel, self).__init__()\n","    # automatcially get the intermediate shape\n","    self.original_embedding_dim = 768\n","    num_heads = 12\n","    mlp_ratio = 4.\n","    qkv_bias = True\n","    qk_norm = False\n","    drop_rate = 0.\n","    attn_drop_rate = 0.\n","    depth = 12\n","\n","\n","    f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n","    num_patches = f_dim * t_dim\n","\n","    self.patch_embed = PatchEmbed()\n","    self.cls_token = nn.Parameter(torch.zeros(1, 1, self.original_embedding_dim))\n","    self.dist_token =  nn.Parameter(torch.zeros(1, 1, self.original_embedding_dim))\n","    # TODO pretrained or sinusoidal\n","    self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 2, self.original_embedding_dim))\n","    \n","    trunc_normal_(self.pos_embed, std=.02)\n","    self.pos_drop = nn.Dropout(p=0.)\n","\n","    self.blocks = nn.Sequential(*[\n","            Block(\n","                self.original_embedding_dim,\n","                num_heads,\n","                mlp_ratio = mlp_ratio,\n","                qkv_bias = qkv_bias,\n","                qk_norm = qk_norm,\n","                drop = drop_rate,\n","                attn_drop = attn_drop_rate,\n","            )\n","            for i in range(depth)])\n","    self.norm =  Norm(self.original_embedding_dim)\n","\n","\n","    # Classifier Head\n","    self.fc_norm = Norm(self.original_embedding_dim) \n","    self.head = nn.Linear(self.original_embedding_dim, label_dim) if label_dim > 0 else nn.Identity()\n","\n","\n","  \n","  @autocast()\n","  def forward(self, x):\n","    x = x.unsqueeze(1)\n","    x = x.transpose(2, 3)\n","    B = x.shape[0]\n","   \n","    x = self.patch_embed(x)\n","    \n","    cls_tokens = self.cls_token.expand(B, -1, -1)\n","    dist_token = self.dist_token.expand(B, -1, -1)\n","\n","    x = torch.cat((cls_tokens, dist_token, x), dim=1)\n","    x = x + self.pos_embed\n","    x = self.pos_drop(x)\n","\n","    x = self.blocks(x)\n","    x = self.norm(x)\n","\n","    x = (x[:, 0] + x[:, 1]) / 2\n","    x = self.fc_norm(x)\n","    x = self.head(x)\n","    return x\n","     \n","\n","  def get_shape(self, fstride, tstride, input_fdim=128, input_tdim=1024):\n","    test_input = torch.randn(1, 1, input_fdim, input_tdim)\n","    test_proj = nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n","    test_out = test_proj(test_input)\n","    f_dim = test_out.shape[2]\n","    t_dim = test_out.shape[3]\n","    return f_dim, t_dim\n"]},{"cell_type":"markdown","metadata":{"id":"QRQH4aX_-EBl"},"source":["# QAST: Parameters as in original paper, no pretraining"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1685718247782,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"LF5PeomvHMtH","outputId":"8ee01dbf-3399-45e9-f173-5d0504c38ec6"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------the train dataloader---------------\n","now using following mask: 48 freq, 48 time\n","now using mix-up with rate 0.600000\n","now process speechcommands\n","use dataset mean -6.846 and std 5.565 to normalize the input.\n","now use noise augmentation\n","number of classes is 35\n","---------------the validation dataloader---------------\n","now using following mask: 0 freq, 0 time\n","now using mix-up with rate 0.000000\n","now process speechcommands\n","use dataset mean -6.846 and std 5.565 to normalize the input.\n","number of classes is 35\n","---------------the validation dataloader---------------\n","now using following mask: 0 freq, 0 time\n","now using mix-up with rate 0.000000\n","now process speechcommands\n","use dataset mean -6.846 and std 5.565 to normalize the input.\n","number of classes is 35\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]}],"source":["data_train = '/content/drive/MyDrive/Thesis/datafiles/speechcommand_train_data.json'\n","data_val_path ='/content/drive/MyDrive/Thesis/datafiles/speechcommand_valid_data.json'\n","data_eval_path ='/content/drive/MyDrive/Thesis/datafiles/speechcommand_eval_data.json'\n","\n","\n","label_csv = '/content/drive/MyDrive/Thesis/ast/egs/speechcommands/data/speechcommands_class_labels_indices.csv'\n","\n","\n","audio_conf = {'num_mel_bins': 128, 'target_length': args.audio_length, 'freqm': args.freqm, 'timem': args.timem, 'mixup': args.mixup, 'dataset': args.dataset, 'mode':'train', 'mean':args.dataset_mean, 'std':args.dataset_std,\n","                  'noise':args.noise}\n","\n","val_audio_conf = {'num_mel_bins': 128, 'target_length': args.audio_length, 'freqm': 0, 'timem': 0, 'mixup': 0, 'dataset': args.dataset, 'mode':'validation', 'mean':args.dataset_mean, 'std':args.dataset_std, 'noise':False}\n","eval_audio_conf = {'num_mel_bins': 128, 'target_length': args.audio_length, 'freqm': 0, 'timem': 0, 'mixup': 0, 'dataset': args.dataset, 'mode':'evaluation', 'mean':args.dataset_mean, 'std':args.dataset_std, 'noise':False}\n","\n","train_loader = torch.utils.data.DataLoader(\n","            dataloader.AudiosetDataset(data_train, label_csv=label_csv, audio_conf=audio_conf),\n","            batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, pin_memory=True)\n","\n","eval_loader = torch.utils.data.DataLoader(\n","        dataloader.AudiosetDataset(data_eval_path, label_csv=label_csv, audio_conf=val_audio_conf),\n","        batch_size=args.batch_size*2, shuffle=False, num_workers=args.num_workers, pin_memory=True)\n","\n","val_loader = torch.utils.data.DataLoader(\n","        dataloader.AudiosetDataset(data_val_path, label_csv=label_csv, audio_conf=val_audio_conf),\n","        batch_size=args.batch_size*2, shuffle=False, num_workers=args.num_workers, pin_memory=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8TARS2GuJJri"},"outputs":[],"source":["ast_mdl = ASTModel(label_dim=args.n_class, fstride=args.fstride, tstride=args.tstride, input_fdim=128,\n","                                input_tdim=args.audio_length, imagenet_pretrain=args.imagenetpretrain,\n","                                audioset_pretrain=args.audiosetpretrain, model_size='base384')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4205,"status":"ok","timestamp":1683555227188,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"chURFTv5qM6n","outputId":"fd22dd22-6635-46a0-dca6-5de883a1fbc1"},"outputs":[{"data":{"text/plain":["ASTModel(\n","  (patch_embed): PatchEmbed(\n","    (projq): QuaternionConv(in_channels=1, out_channels=192, bias=True, kernel_size=(16, 16), stride=10, padding=0, init_criterion=glorot, weight_init=quaternion, seed=1158, rotation=False, q_format=True, operation=convolution2d)\n","  )\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (blocks): Sequential(\n","    (0): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=694)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=764)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=521)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=758)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (1): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=829)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1106)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=657)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=373)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (2): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=954)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=148)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=636)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=962)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (3): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=766)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=480)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=265)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=372)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (4): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1091)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=401)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=331)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=197)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (5): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=855)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=484)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=718)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=726)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (6): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=9)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=24)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=916)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=290)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (7): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=566)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=156)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=988)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=889)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (8): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=48)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=163)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=687)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=81)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (9): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=102)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1116)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1184)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=822)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (10): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=21)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1229)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=267)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=784)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","    (11): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1194)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=827)\n","        (proj_drop): Dropout(p=0.0, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=137)\n","        (drop1): Dropout(p=0.0, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=331)\n","        (drop2): Dropout(p=0.0, inplace=False)\n","      )\n","    )\n","  )\n","  (norm): Norm()\n","  (fc_norm): Norm()\n","  (head): Linear(in_features=768, out_features=35, bias=True)\n",")"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["ast_mdl.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2895588,"status":"ok","timestamp":1681487742305,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"2hrUf8xs04Bc","outputId":"ec894968-c9d3-4d21-c4bf-661d6b2ea353"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now starting training for 20 epochs\n","running on cuda\n","Total parameter number is : 21.665 million\n","Total trainable parameter number is : 21.665 million\n","now training with speechcommands, main metrics: acc, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f294d682c10>\n","The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n","current #steps=0, #epochs=1\n","start training...\n","---------------\n","2023-04-14 13:27:12.379812\n","current #epochs=1, #steps=0\n","Epoch: [1][100/662]\tPer Sample Total Time 0.00529\tPer Sample Data Time 0.00042\tPer Sample DNN Time 0.00487\tTrain Loss 0.1286\t\n","Epoch: [1][200/662]\tPer Sample Total Time 0.00508\tPer Sample Data Time 0.00021\tPer Sample DNN Time 0.00487\tTrain Loss 0.1285\t\n","Epoch: [1][300/662]\tPer Sample Total Time 0.00500\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.00486\tTrain Loss 0.1283\t\n","Epoch: [1][400/662]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.00486\tTrain Loss 0.1281\t\n","Epoch: [1][500/662]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.1279\t\n","Epoch: [1][600/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.1278\t\n","start validation\n","acc: 0.069933\n","AUC: 0.624922\n","Avg Precision: 0.059670\n","Avg Recall: 0.964399\n","d_prime: 0.450335\n","train_loss: 0.127691\n","valid_loss: 0.126086\n","validation finished\n","Epoch-1 lr: 0.00025\n","epoch 1 training time: 446.269\n","---------------\n","2023-04-14 13:34:38.649073\n","current #epochs=2, #steps=662\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][38/662]\tPer Sample Total Time 0.00593\tPer Sample Data Time 0.00105\tPer Sample DNN Time 0.00488\tTrain Loss 0.1269\t\n","Epoch: [2][138/662]\tPer Sample Total Time 0.00516\tPer Sample Data Time 0.00030\tPer Sample DNN Time 0.00486\tTrain Loss 0.1267\t\n","Epoch: [2][238/662]\tPer Sample Total Time 0.00503\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.00486\tTrain Loss 0.1266\t\n","Epoch: [2][338/662]\tPer Sample Total Time 0.00498\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.00486\tTrain Loss 0.1265\t\n","Epoch: [2][438/662]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00486\tTrain Loss 0.1263\t\n","Epoch: [2][538/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.1260\t\n","Epoch: [2][638/662]\tPer Sample Total Time 0.00492\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.1257\t\n","start validation\n","acc: 0.166015\n","AUC: 0.762052\n","Avg Precision: 0.081434\n","Avg Recall: 0.675836\n","d_prime: 1.008222\n","train_loss: 0.125621\n","valid_loss: 0.115947\n","validation finished\n","Epoch-2 lr: 0.00025\n","epoch 2 training time: 446.466\n","---------------\n","2023-04-14 13:42:05.115495\n","current #epochs=3, #steps=1324\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][76/662]\tPer Sample Total Time 0.00543\tPer Sample Data Time 0.00056\tPer Sample DNN Time 0.00487\tTrain Loss 0.1223\t\n","Epoch: [3][176/662]\tPer Sample Total Time 0.00511\tPer Sample Data Time 0.00025\tPer Sample DNN Time 0.00486\tTrain Loss 0.1221\t\n","Epoch: [3][276/662]\tPer Sample Total Time 0.00502\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.00486\tTrain Loss 0.1217\t\n","Epoch: [3][376/662]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.00486\tTrain Loss 0.1214\t\n","Epoch: [3][476/662]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.1209\t\n","Epoch: [3][576/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.1206\t\n","start validation\n","acc: 0.267208\n","AUC: 0.874567\n","Avg Precision: 0.113632\n","Avg Recall: 0.729903\n","d_prime: 1.623866\n","train_loss: 0.120348\n","valid_loss: 0.099219\n","validation finished\n","Epoch-3 lr: 0.00025\n","epoch 3 training time: 445.494\n","---------------\n","2023-04-14 13:49:30.609337\n","current #epochs=4, #steps=1986\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][14/662]\tPer Sample Total Time 0.00767\tPer Sample Data Time 0.00276\tPer Sample DNN Time 0.00491\tTrain Loss 0.1175\t\n","Epoch: [4][114/662]\tPer Sample Total Time 0.00523\tPer Sample Data Time 0.00036\tPer Sample DNN Time 0.00486\tTrain Loss 0.1166\t\n","Epoch: [4][214/662]\tPer Sample Total Time 0.00506\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.00486\tTrain Loss 0.1162\t\n","Epoch: [4][314/662]\tPer Sample Total Time 0.00499\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.00486\tTrain Loss 0.1159\t\n","Epoch: [4][414/662]\tPer Sample Total Time 0.00496\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00486\tTrain Loss 0.1152\t\n","Epoch: [4][514/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.1146\t\n","Epoch: [4][614/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.1141\t\n","start validation\n","acc: 0.499750\n","AUC: 0.946366\n","Avg Precision: 0.109597\n","Avg Recall: 0.922931\n","d_prime: 2.277723\n","train_loss: 0.113788\n","valid_loss: 0.076661\n","validation finished\n","Epoch-4 lr: 0.00025\n","epoch 4 training time: 445.258\n","---------------\n","2023-04-14 13:56:55.866991\n","current #epochs=5, #steps=2648\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [5][52/662]\tPer Sample Total Time 0.00563\tPer Sample Data Time 0.00076\tPer Sample DNN Time 0.00487\tTrain Loss 0.1109\t\n","Epoch: [5][152/662]\tPer Sample Total Time 0.00513\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.00486\tTrain Loss 0.1095\t\n","Epoch: [5][252/662]\tPer Sample Total Time 0.00502\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.00486\tTrain Loss 0.1090\t\n","Epoch: [5][352/662]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.00486\tTrain Loss 0.1086\t\n","Epoch: [5][452/662]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.1081\t\n","Epoch: [5][552/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.1077\t\n","Epoch: [5][652/662]\tPer Sample Total Time 0.00492\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00486\tTrain Loss 0.1073\t\n","start validation\n","acc: 0.627592\n","AUC: 0.969998\n","Avg Precision: 0.111862\n","Avg Recall: 0.966746\n","d_prime: 2.659792\n","train_loss: 0.107254\n","valid_loss: 0.061436\n","validation finished\n","Epoch-5 lr: 0.0002125\n","epoch 5 training time: 445.215\n","---------------\n","2023-04-14 14:04:21.081879\n","current #epochs=6, #steps=3310\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [6][90/662]\tPer Sample Total Time 0.00533\tPer Sample Data Time 0.00046\tPer Sample DNN Time 0.00487\tTrain Loss 0.1036\t\n","Epoch: [6][190/662]\tPer Sample Total Time 0.00508\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.00486\tTrain Loss 0.1034\t\n","Epoch: [6][290/662]\tPer Sample Total Time 0.00500\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.00486\tTrain Loss 0.1032\t\n","Epoch: [6][390/662]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.00486\tTrain Loss 0.1030\t\n","Epoch: [6][490/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.1027\t\n","Epoch: [6][590/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.1024\t\n","start validation\n","acc: 0.688709\n","AUC: 0.979370\n","Avg Precision: 0.122149\n","Avg Recall: 0.977230\n","d_prime: 2.886283\n","train_loss: 0.102152\n","valid_loss: 0.052821\n","validation finished\n","Epoch-6 lr: 0.00018062499999999999\n","epoch 6 training time: 445.633\n","---------------\n","2023-04-14 14:11:46.714771\n","current #epochs=7, #steps=3972\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [7][28/662]\tPer Sample Total Time 0.00635\tPer Sample Data Time 0.00146\tPer Sample DNN Time 0.00489\tTrain Loss 0.1004\t\n","Epoch: [7][128/662]\tPer Sample Total Time 0.00520\tPer Sample Data Time 0.00033\tPer Sample DNN Time 0.00487\tTrain Loss 0.0996\t\n","Epoch: [7][228/662]\tPer Sample Total Time 0.00505\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.00486\tTrain Loss 0.0992\t\n","Epoch: [7][328/662]\tPer Sample Total Time 0.00499\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.00486\tTrain Loss 0.0987\t\n","Epoch: [7][428/662]\tPer Sample Total Time 0.00496\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00486\tTrain Loss 0.0986\t\n","Epoch: [7][528/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0985\t\n","Epoch: [7][628/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.0983\t\n","start validation\n","acc: 0.749224\n","AUC: 0.984162\n","Avg Precision: 0.131088\n","Avg Recall: 0.983804\n","d_prime: 3.038399\n","train_loss: 0.098223\n","valid_loss: 0.045650\n","validation finished\n","Epoch-7 lr: 0.00015353125\n","epoch 7 training time: 445.450\n","---------------\n","2023-04-14 14:19:12.164561\n","current #epochs=8, #steps=4634\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [8][66/662]\tPer Sample Total Time 0.00553\tPer Sample Data Time 0.00064\tPer Sample DNN Time 0.00489\tTrain Loss 0.0959\t\n","Epoch: [8][166/662]\tPer Sample Total Time 0.00513\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.00487\tTrain Loss 0.0956\t\n","Epoch: [8][266/662]\tPer Sample Total Time 0.00503\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.00487\tTrain Loss 0.0956\t\n","Epoch: [8][366/662]\tPer Sample Total Time 0.00498\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.00486\tTrain Loss 0.0954\t\n","Epoch: [8][466/662]\tPer Sample Total Time 0.00496\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.0952\t\n","Epoch: [8][566/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0951\t\n","start validation\n","acc: 0.787496\n","AUC: 0.988140\n","Avg Precision: 0.152898\n","Avg Recall: 0.983553\n","d_prime: 3.198438\n","train_loss: 0.094976\n","valid_loss: 0.041402\n","validation finished\n","Epoch-8 lr: 0.0001305015625\n","epoch 8 training time: 445.998\n","---------------\n","2023-04-14 14:26:38.162726\n","current #epochs=9, #steps=5296\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [9][4/662]\tPer Sample Total Time 0.01290\tPer Sample Data Time 0.00790\tPer Sample DNN Time 0.00499\tTrain Loss 0.0926\t\n","Epoch: [9][104/662]\tPer Sample Total Time 0.00526\tPer Sample Data Time 0.00038\tPer Sample DNN Time 0.00488\tTrain Loss 0.0937\t\n","Epoch: [9][204/662]\tPer Sample Total Time 0.00507\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.00487\tTrain Loss 0.0936\t\n","Epoch: [9][304/662]\tPer Sample Total Time 0.00500\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.00487\tTrain Loss 0.0932\t\n","Epoch: [9][404/662]\tPer Sample Total Time 0.00496\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00486\tTrain Loss 0.0932\t\n","Epoch: [9][504/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0930\t\n","Epoch: [9][604/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.0929\t\n","start validation\n","acc: 0.813646\n","AUC: 0.989919\n","Avg Precision: 0.142750\n","Avg Recall: 0.988840\n","d_prime: 3.285674\n","train_loss: 0.092778\n","valid_loss: 0.036659\n","validation finished\n","Epoch-9 lr: 0.00011092632812499999\n","epoch 9 training time: 445.697\n","---------------\n","2023-04-14 14:34:03.859652\n","current #epochs=10, #steps=5958\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [10][42/662]\tPer Sample Total Time 0.00580\tPer Sample Data Time 0.00092\tPer Sample DNN Time 0.00488\tTrain Loss 0.0917\t\n","Epoch: [10][142/662]\tPer Sample Total Time 0.00515\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.00488\tTrain Loss 0.0917\t\n","Epoch: [10][242/662]\tPer Sample Total Time 0.00503\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.00487\tTrain Loss 0.0912\t\n","Epoch: [10][342/662]\tPer Sample Total Time 0.00498\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.00486\tTrain Loss 0.0910\t\n","Epoch: [10][442/662]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.0911\t\n","Epoch: [10][542/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0909\t\n","Epoch: [10][642/662]\tPer Sample Total Time 0.00492\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00486\tTrain Loss 0.0908\t\n","start validation\n","acc: 0.831079\n","AUC: 0.991295\n","Avg Precision: 0.151957\n","Avg Recall: 0.988305\n","d_prime: 3.362889\n","train_loss: 0.090795\n","valid_loss: 0.034488\n","validation finished\n","Epoch-10 lr: 9.428737890624999e-05\n","epoch 10 training time: 446.241\n","---------------\n","2023-04-14 14:41:30.100899\n","current #epochs=11, #steps=6620\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [11][80/662]\tPer Sample Total Time 0.00536\tPer Sample Data Time 0.00049\tPer Sample DNN Time 0.00487\tTrain Loss 0.0896\t\n","Epoch: [11][180/662]\tPer Sample Total Time 0.00509\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.00487\tTrain Loss 0.0895\t\n","Epoch: [11][280/662]\tPer Sample Total Time 0.00500\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.00486\tTrain Loss 0.0895\t\n","Epoch: [11][380/662]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.00486\tTrain Loss 0.0893\t\n","Epoch: [11][480/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.0894\t\n","Epoch: [11][580/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.0893\t\n","start validation\n","acc: 0.839295\n","AUC: 0.992733\n","Avg Precision: 0.156091\n","Avg Recall: 0.991426\n","d_prime: 3.456014\n","train_loss: 0.089319\n","valid_loss: 0.032713\n","validation finished\n","Epoch-11 lr: 8.014427207031248e-05\n","epoch 11 training time: 444.919\n","---------------\n","2023-04-14 14:48:55.020225\n","current #epochs=12, #steps=7282\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [12][18/662]\tPer Sample Total Time 0.00707\tPer Sample Data Time 0.00215\tPer Sample DNN Time 0.00492\tTrain Loss 0.0871\t\n","Epoch: [12][118/662]\tPer Sample Total Time 0.00521\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.00486\tTrain Loss 0.0879\t\n","Epoch: [12][218/662]\tPer Sample Total Time 0.00505\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.00486\tTrain Loss 0.0881\t\n","Epoch: [12][318/662]\tPer Sample Total Time 0.00499\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.00486\tTrain Loss 0.0881\t\n","Epoch: [12][418/662]\tPer Sample Total Time 0.00496\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00486\tTrain Loss 0.0881\t\n","Epoch: [12][518/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0880\t\n","Epoch: [12][618/662]\tPer Sample Total Time 0.00492\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.0880\t\n","start validation\n","acc: 0.850616\n","AUC: 0.993441\n","Avg Precision: 0.161787\n","Avg Recall: 0.992148\n","d_prime: 3.508011\n","train_loss: 0.088010\n","valid_loss: 0.030273\n","validation finished\n","Epoch-12 lr: 6.81226312597656e-05\n","epoch 12 training time: 445.204\n","---------------\n","2023-04-14 14:56:20.224368\n","current #epochs=13, #steps=7944\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [13][56/662]\tPer Sample Total Time 0.00558\tPer Sample Data Time 0.00071\tPer Sample DNN Time 0.00487\tTrain Loss 0.0871\t\n","Epoch: [13][156/662]\tPer Sample Total Time 0.00512\tPer Sample Data Time 0.00026\tPer Sample DNN Time 0.00486\tTrain Loss 0.0872\t\n","Epoch: [13][256/662]\tPer Sample Total Time 0.00502\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.00486\tTrain Loss 0.0873\t\n","Epoch: [13][356/662]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.00486\tTrain Loss 0.0872\t\n","Epoch: [13][456/662]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.0872\t\n","Epoch: [13][556/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0871\t\n","Epoch: [13][656/662]\tPer Sample Total Time 0.00492\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00485\tTrain Loss 0.0871\t\n","start validation\n","acc: 0.849013\n","AUC: 0.993584\n","Avg Precision: 0.169255\n","Avg Recall: 0.990889\n","d_prime: 3.519132\n","train_loss: 0.087066\n","valid_loss: 0.030300\n","validation finished\n","Epoch-13 lr: 5.7904236570800764e-05\n","epoch 13 training time: 444.174\n","---------------\n","2023-04-14 15:03:44.398021\n","current #epochs=14, #steps=8606\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [14][94/662]\tPer Sample Total Time 0.00533\tPer Sample Data Time 0.00047\tPer Sample DNN Time 0.00486\tTrain Loss 0.0863\t\n","Epoch: [14][194/662]\tPer Sample Total Time 0.00509\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.00486\tTrain Loss 0.0861\t\n","Epoch: [14][294/662]\tPer Sample Total Time 0.00501\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.00486\tTrain Loss 0.0860\t\n","Epoch: [14][394/662]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.00486\tTrain Loss 0.0860\t\n","Epoch: [14][494/662]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.0861\t\n","Epoch: [14][594/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0860\t\n","start validation\n","acc: 0.865645\n","AUC: 0.994108\n","Avg Precision: 0.183916\n","Avg Recall: 0.991201\n","d_prime: 3.561724\n","train_loss: 0.086149\n","valid_loss: 0.028464\n","validation finished\n","Epoch-14 lr: 4.921860108518065e-05\n","epoch 14 training time: 445.616\n","---------------\n","2023-04-14 15:11:10.013851\n","current #epochs=15, #steps=9268\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [15][32/662]\tPer Sample Total Time 0.00619\tPer Sample Data Time 0.00130\tPer Sample DNN Time 0.00489\tTrain Loss 0.0856\t\n","Epoch: [15][132/662]\tPer Sample Total Time 0.00519\tPer Sample Data Time 0.00033\tPer Sample DNN Time 0.00486\tTrain Loss 0.0856\t\n","Epoch: [15][232/662]\tPer Sample Total Time 0.00504\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.00486\tTrain Loss 0.0853\t\n","Epoch: [15][332/662]\tPer Sample Total Time 0.00499\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.00486\tTrain Loss 0.0852\t\n","Epoch: [15][432/662]\tPer Sample Total Time 0.00496\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00486\tTrain Loss 0.0851\t\n","Epoch: [15][532/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0850\t\n","Epoch: [15][632/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.0851\t\n","start validation\n","acc: 0.868149\n","AUC: 0.994447\n","Avg Precision: 0.171821\n","Avg Recall: 0.991884\n","d_prime: 3.591173\n","train_loss: 0.085022\n","valid_loss: 0.027628\n","validation finished\n","Epoch-15 lr: 4.183581092240355e-05\n","epoch 15 training time: 445.450\n","---------------\n","2023-04-14 15:18:35.464215\n","current #epochs=16, #steps=9930\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [16][70/662]\tPer Sample Total Time 0.00545\tPer Sample Data Time 0.00058\tPer Sample DNN Time 0.00487\tTrain Loss 0.0841\t\n","Epoch: [16][170/662]\tPer Sample Total Time 0.00510\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.00486\tTrain Loss 0.0845\t\n","Epoch: [16][270/662]\tPer Sample Total Time 0.00501\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.00486\tTrain Loss 0.0847\t\n","Epoch: [16][370/662]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.00486\tTrain Loss 0.0846\t\n","Epoch: [16][470/662]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.0846\t\n","Epoch: [16][570/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0846\t\n","start validation\n","acc: 0.870053\n","AUC: 0.994638\n","Avg Precision: 0.172907\n","Avg Recall: 0.993313\n","d_prime: 3.608478\n","train_loss: 0.084520\n","valid_loss: 0.027097\n","validation finished\n","Epoch-16 lr: 3.556043928404302e-05\n","epoch 16 training time: 445.340\n","---------------\n","2023-04-14 15:26:00.804832\n","current #epochs=17, #steps=10592\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [17][8/662]\tPer Sample Total Time 0.00947\tPer Sample Data Time 0.00451\tPer Sample DNN Time 0.00496\tTrain Loss 0.0841\t\n","Epoch: [17][108/662]\tPer Sample Total Time 0.00524\tPer Sample Data Time 0.00037\tPer Sample DNN Time 0.00486\tTrain Loss 0.0846\t\n","Epoch: [17][208/662]\tPer Sample Total Time 0.00505\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.00486\tTrain Loss 0.0844\t\n","Epoch: [17][308/662]\tPer Sample Total Time 0.00499\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.00486\tTrain Loss 0.0843\t\n","Epoch: [17][408/662]\tPer Sample Total Time 0.00496\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00486\tTrain Loss 0.0843\t\n","Epoch: [17][508/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0841\t\n","Epoch: [17][608/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.0840\t\n","start validation\n","acc: 0.874461\n","AUC: 0.994886\n","Avg Precision: 0.178615\n","Avg Recall: 0.993522\n","d_prime: 3.631712\n","train_loss: 0.083993\n","valid_loss: 0.026226\n","validation finished\n","Epoch-17 lr: 3.0226373391436563e-05\n","epoch 17 training time: 445.247\n","---------------\n","2023-04-14 15:33:26.052061\n","current #epochs=18, #steps=11254\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [18][46/662]\tPer Sample Total Time 0.00572\tPer Sample Data Time 0.00085\tPer Sample DNN Time 0.00487\tTrain Loss 0.0842\t\n","Epoch: [18][146/662]\tPer Sample Total Time 0.00513\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.00486\tTrain Loss 0.0839\t\n","Epoch: [18][246/662]\tPer Sample Total Time 0.00502\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.00486\tTrain Loss 0.0839\t\n","Epoch: [18][346/662]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.00485\tTrain Loss 0.0838\t\n","Epoch: [18][446/662]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00486\tTrain Loss 0.0837\t\n","Epoch: [18][546/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00486\tTrain Loss 0.0836\t\n","Epoch: [18][646/662]\tPer Sample Total Time 0.00492\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.00485\tTrain Loss 0.0835\t\n","start validation\n","acc: 0.877467\n","AUC: 0.995062\n","Avg Precision: 0.177008\n","Avg Recall: 0.993388\n","d_prime: 3.648861\n","train_loss: 0.083513\n","valid_loss: 0.025870\n","validation finished\n","Epoch-18 lr: 2.5692417382721078e-05\n","epoch 18 training time: 445.296\n","---------------\n","2023-04-14 15:40:51.347851\n","current #epochs=19, #steps=11916\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [19][84/662]\tPer Sample Total Time 0.00535\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.00486\tTrain Loss 0.0830\t\n","Epoch: [19][184/662]\tPer Sample Total Time 0.00508\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.00486\tTrain Loss 0.0832\t\n","Epoch: [19][284/662]\tPer Sample Total Time 0.00500\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.00486\tTrain Loss 0.0832\t\n","Epoch: [19][384/662]\tPer Sample Total Time 0.00496\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.00486\tTrain Loss 0.0833\t\n","Epoch: [19][484/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.00485\tTrain Loss 0.0832\t\n","Epoch: [19][584/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00486\tTrain Loss 0.0833\t\n","start validation\n","acc: 0.879471\n","AUC: 0.995279\n","Avg Precision: 0.189474\n","Avg Recall: 0.993201\n","d_prime: 3.670778\n","train_loss: 0.083203\n","valid_loss: 0.025681\n","validation finished\n","Epoch-19 lr: 2.1838554775312915e-05\n","epoch 19 training time: 446.218\n","---------------\n","2023-04-14 15:48:17.565845\n","current #epochs=20, #steps=12578\n"]},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 12, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [20][22/662]\tPer Sample Total Time 0.00675\tPer Sample Data Time 0.00185\tPer Sample DNN Time 0.00490\tTrain Loss 0.0831\t\n","Epoch: [20][122/662]\tPer Sample Total Time 0.00521\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.00486\tTrain Loss 0.0823\t\n","Epoch: [20][222/662]\tPer Sample Total Time 0.00505\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.00486\tTrain Loss 0.0826\t\n","Epoch: [20][322/662]\tPer Sample Total Time 0.00499\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.00486\tTrain Loss 0.0825\t\n","Epoch: [20][422/662]\tPer Sample Total Time 0.00496\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.00485\tTrain Loss 0.0826\t\n","Epoch: [20][522/662]\tPer Sample Total Time 0.00494\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.00485\tTrain Loss 0.0827\t\n","Epoch: [20][622/662]\tPer Sample Total Time 0.00493\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.00485\tTrain Loss 0.0827\t\n","start validation\n","acc: 0.879271\n","AUC: 0.995434\n","Avg Precision: 0.178181\n","Avg Recall: 0.994049\n","d_prime: 3.686999\n","train_loss: 0.082715\n","valid_loss: 0.025525\n","validation finished\n","Epoch-20 lr: 1.8562771559015977e-05\n","epoch 20 training time: 444.494\n"]}],"source":["print('Now starting training for {:d} epochs'.format(args.n_epochs))\n","\n","train(ast_mdl, train_loader, val_loader, args)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArXCqvLNJ_Tq"},"outputs":[],"source":["# # Model checker\n","# ast_mdl.train()\n","\n","# for i, (audio_input, labels) in enumerate(train_loader):\n","\n","#     print(str(i)+'th instance')\n","\n","#     B = audio_input.size(0)\n","#     audio_input = audio_input.to(device, non_blocking=True)\n","#     labels = labels.to(device, non_blocking=True)\n","\n","#     with autocast():\n","#         audio_output = ast_mdl(audio_input)\n","#     print(\"Output shape\", audio_output.shape)\n","#     print(\"Done\")\n","#     break"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1683555228480,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"AYVNm6KBDpCu","outputId":"23c51392-d0e5-4aba-9488-11823298f1b0"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/Thesis/resout_qast/models/best_audio_model.pth'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["args.exp_dir + '/models/best_audio_model.pth'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4067,"status":"ok","timestamp":1683555232543,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"g8tu81LtDuM8","outputId":"091c910c-2392-4b17-c0a2-b9a61b54ac68"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","sd = torch.load(args.exp_dir + '/models/best_audio_model.pth', map_location=device)\n","audio_model = torch.nn.DataParallel(ast_mdl)\n","audio_model.load_state_dict(sd)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":343,"status":"ok","timestamp":1683555237629,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"HpeXWLFBsId0","outputId":"da931217-ac34-4500-b0ba-e53a01d057ad"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'BCE'"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["args.loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f_cGFsOxYFku"},"outputs":[],"source":["loss_fn = nn.BCEWithLogitsLoss()\n","args.loss_fn = loss_fn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":287414,"status":"ok","timestamp":1683555530259,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"BO42MMIGD9k5","outputId":"5ddf6260-a4ce-40d2-8ebc-74a107fe1e68"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------evaluate on the validation set---------------\n","Accuracy: 0.879371\n","AUC: 0.995279\n"]}],"source":["import numpy as np\n","# best model on the validation set\n","stats, _ = validate(audio_model, val_loader, args, 'valid_set')\n","# note it is NOT mean of class-wise accuracy\n","val_acc = stats[0]['acc']\n","val_mAUC = np.mean([stat['auc'] for stat in stats])\n","print('---------------evaluate on the validation set---------------')\n","print(\"Accuracy: {:.6f}\".format(val_acc))\n","print(\"AUC: {:.6f}\".format(val_mAUC))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1683555805695,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"BZmXWvlIvsGx","outputId":"663ec08f-848d-4cac-a45d-7a4a753d4c28"},"outputs":[{"data":{"text/plain":["{'precisions': array([0.01499318, 0.07860886]),\n"," 'recalls': array([1., 1.]),\n"," 'AP': 0.9278634102889988,\n"," 'fpr': array([0.        , 0.61411439]),\n"," 'fnr': array([1., 0.]),\n"," 'auc': 0.9971687353237169,\n"," 'acc': 0.8675147660154475}"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["stats[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":460,"status":"ok","timestamp":1683555828900,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"C0R9FGagEGvp","outputId":"e97e878b-3df9-4b2d-971d-c6d0816ea3ea"},"outputs":[{"name":"stdout","output_type":"stream","text":["---------------evaluate on the test set---------------\n","Accuracy: 0.867515\n","AUC: 0.994489\n"]}],"source":["# test the model on the evaluation set\n","stats, _ = validate(audio_model, eval_loader, args, 'eval_set')\n","eval_acc = stats[0]['acc']\n","eval_mAUC = np.mean([stat['auc'] for stat in stats])\n","print('---------------evaluate on the test set---------------')\n","print(\"Accuracy: {:.6f}\".format(eval_acc))\n","print(\"AUC: {:.6f}\".format(eval_mAUC))\n","np.savetxt(args.exp_dir + '/eval_result.csv', [val_acc, val_mAUC, eval_acc, eval_mAUC])"]},{"cell_type":"markdown","metadata":{"id":"BwHxofCSIuAy"},"source":["# Pretraining QAST on Images"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"EqVh9xerJMkB","executionInfo":{"status":"ok","timestamp":1686573847306,"user_tz":-120,"elapsed":4,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["\"\"\"\n","Preprocessing:\n","img and label\n","for label int to one hot convert is below\n","\"\"\"\n","\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","\n","def transforms_(examples):\n","    if 'img' in examples:\n","      examples[\"image\"] = [image.convert(\"RGB\").resize((128,128)) for image in examples['img']] #32\n","      return examples\n","    elif 'image' in examples:\n","      examples[\"image\"] = [image.convert(\"RGB\").resize((64,64)) for image in examples['image']]\n","      return examples\n","    else:\n","      print(\"please check the dataset keys\")\n","    \n","\n","def collate_fn(examples):\n","    images = []\n","    labels = []\n","    convert_tensor = transforms.ToTensor()\n","\n","    for example in examples:\n","        images.append(convert_tensor(example[\"image\"]))\n","        labels.append(example[\"label\"])\n","        \n","    pixel_values = torch.stack(images)\n","    labels = torch.tensor(labels)\n","\n","    b_size = labels.shape[0]\n","    n_classes = args_pretraining.n_classes\n","    y = torch.zeros(b_size, n_classes)\n","    y[range(y.shape[0]), labels]=1\n","    return (pixel_values, y)"]},{"cell_type":"code","execution_count":29,"metadata":{"id":"bjN3DlcB-Wn8","executionInfo":{"status":"ok","timestamp":1686573901713,"user_tz":-120,"elapsed":347,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["import torch\n","import torchvision\n","import timm\n","from enum import Enum\n","from typing import Union\n","\n","class Format(str, Enum):\n","    NCHW = 'NCHW'\n","    NHWC = 'NHWC'\n","    NCL = 'NCL'\n","    NLC = 'NLC'\n","\n","\n","FormatT = Union[str, Format]\n","\n","\n","def get_spatial_dim(fmt: FormatT):\n","    fmt = Format(fmt)\n","    if fmt is Format.NLC:\n","        dim = (1,)\n","    elif fmt is Format.NCL:\n","        dim = (2,)\n","    elif fmt is Format.NHWC:\n","        dim = (1, 2)\n","    else:\n","        dim = (2, 3)\n","    return dim\n","\n","\n","def get_channel_dim(fmt: FormatT):\n","    fmt = Format(fmt)\n","    if fmt is Format.NHWC:\n","        dim = 3\n","    elif fmt is Format.NLC:\n","        dim = 2\n","    else:\n","        dim = 1\n","    return dim\n","\n","\n","def nchw_to(x: torch.Tensor, fmt: Format):\n","    if fmt == Format.NHWC:\n","        x = x.permute(0, 2, 3, 1)\n","    elif fmt == Format.NLC:\n","        x = x.flatten(2).transpose(1, 2)\n","    elif fmt == Format.NCL:\n","        x = x.flatten(2)\n","    return x\n","\n","\n","def nhwc_to(x: torch.Tensor, fmt: Format):\n","    if fmt == Format.NCHW:\n","        x = x.permute(0, 3, 1, 2)\n","    elif fmt == Format.NLC:\n","        x = x.flatten(1, 2)\n","    elif fmt == Format.NCL:\n","        x = x.flatten(1, 2).transpose(1, 2)\n","    return\n","\n","import logging\n","from typing import List, Optional, Callable\n","\n","import torch\n","from torch import nn as nn\n","from torch import _assert\n","import torch.nn.functional as F\n","\n","_logger = logging.getLogger(__name__)\n","\n","\n","class PatchEmbedding(nn.Module):\n","    \"\"\" 2D Image to Patch Embedding\n","    \"\"\"\n","    output_fmt: Format\n","\n","    def __init__(\n","            self,\n","            img_size: Optional[int] = 32,\n","            patch_size: int = 16,\n","            in_chans: int = 4,\n","            embed_dim: int = 768,\n","            norm_layer: Optional[Callable] = None,\n","            flatten: bool = True,\n","            output_fmt: Optional[str] = None,\n","            bias: bool = True,\n","    ):\n","        super().__init__()\n","        self.patch_size = to_2tuple(patch_size)\n","        if img_size is not None:\n","            self.img_size = to_2tuple(img_size)\n","            self.grid_size = tuple([s // p for s, p in zip(self.img_size, self.patch_size)])\n","            self.num_patches = self.grid_size[0] * self.grid_size[1]\n","        else:\n","            self.img_size = None\n","            self.grid_size = None\n","            self.num_patches = None\n","\n","        if output_fmt is not None:\n","            self.flatten = False\n","            self.output_fmt = Format(output_fmt)\n","        else:\n","            # flatten spatial dim and transpose to channels last, kept for bwd compat\n","            self.flatten = flatten\n","            self.output_fmt = Format.NCHW\n","\n","        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size, bias=bias)\n","        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n","\n","    def forward(self, x):\n","        B, C, H, W = x.shape\n","        if self.img_size is not None:\n","            _assert(H == self.img_size[0], f\"Input image height ({H}) doesn't match model ({self.img_size[0]}).\")\n","            _assert(W == self.img_size[1], f\"Input image width ({W}) doesn't match model ({self.img_size[1]}).\")\n","        \n","        zeros = torch.zeros((B, 1, H, W)).to(device)\n","        x = torch.cat((zeros, x), 1)\n","        x = self.proj(x)\n","        if self.flatten:\n","            x = x.flatten(2).transpose(1, 2)  # NCHW -> NLC\n","        elif self.output_fmt != Format.NCHW:\n","            x = nchw_to(x, self.output_fmt)\n","        x = self.norm(x)\n","        return x\n","\n"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"shfI-jDaRb3P","executionInfo":{"status":"ok","timestamp":1686573906534,"user_tz":-120,"elapsed":414,"user":{"displayName":"Bota D","userId":"04482539542256056244"}}},"outputs":[],"source":["# create a folder for results: predictions and models\n","# create target.csv\n","\n","import os\n","import csv\n","import shutil\n","\n","def create_target_csv(path, val_data):\n","  out_target = []\n","  for test in val_data:\n","    out_target.extend(test[1].tolist())\n","  # print(len(out_target))\n","\n","  with open(os.path.join(path, \"target.csv\"), 'w') as f:\n","    write = csv.writer(f)\n","    write.writerows(out_target)\n","\n","def prepare_result_saving(args, val_data = None):\n","  if not os.path.exists(args.exp_dir, ):\n","      # if the demo_folder directory is not present \n","      # then create it.\n","      os.makedirs(args.exp_dir)\n","      os.makedirs(os.path.join(args.exp_dir, \"models\"))\n","      os.makedirs(os.path.join(args.exp_dir, \"predictions\"))\n","      print(\"Created folders\")\n","  else:\n","      print(\"Folders already exists\")\n","  if not os.path.exists(os.path.join(args.exp_dir, \"predictions\",\"target.csv\")):\n","    if val_data!= None:\n","      create_target_csv(os.path.join(args.exp_dir, \"predictions\"), val_data)\n","    else:\n","      shutil.copy('/content/drive/MyDrive/Thesis/resout_qast/predictions/target.csv', os.path.join(args.exp_dir, \"predictions\") ) \n","      print(\"copied target\")\n","  else:\n","      print(\"Target.csv already exists\")\n"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1686573907846,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"fRCKVOwg3Y4x"},"outputs":[],"source":["class QVIT(nn.Module):\n","  def __init__(self, label_dim=200, img_size=32, verbose=True):\n","    super(QVIT, self).__init__()\n","    # automatcially get the intermediate shape\n","    self.original_embedding_dim = 768\n","    num_heads = 12\n","    mlp_ratio = 4.\n","    qkv_bias = True\n","    qk_norm = False\n","    drop_rate = 0.1\n","    attn_drop_rate = 0.\n","    depth = 12\n","    self.patch_embed = PatchEmbedding(\n","            img_size = img_size,\n","            patch_size=16,\n","            in_chans=4,\n","            embed_dim=self.original_embedding_dim,\n","        )\n","    num_patches = self.patch_embed.num_patches\n","\n","\n","    self.cls_token = nn.Parameter(torch.zeros(1, 1, self.original_embedding_dim))\n","    self.dist_token =  nn.Parameter(torch.zeros(1, 1, self.original_embedding_dim))\n","    # TODO pretrained or sinusoidal\n","    self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 2, self.original_embedding_dim))\n","    \n","    trunc_normal_(self.pos_embed, std=.02)\n","    self.pos_drop = nn.Dropout(p=0.)\n","\n","    self.blocks = nn.Sequential(*[\n","            Block(\n","                self.original_embedding_dim,\n","                num_heads,\n","                mlp_ratio = mlp_ratio,\n","                qkv_bias = qkv_bias,\n","                qk_norm = qk_norm,\n","                drop = drop_rate,\n","                attn_drop = attn_drop_rate,\n","            )\n","            for i in range(depth)])\n","    self.norm =  Norm(self.original_embedding_dim)\n","\n","    # Classifier Head\n","    self.fc_norm = Norm(self.original_embedding_dim) \n","    self.head = nn.Linear(self.original_embedding_dim, label_dim) if label_dim > 0 else nn.Identity()\n","\n","  \n","  @autocast()\n","  def forward(self, x):\n","    B = x.shape[0]\n","    x = self.patch_embed(x)\n","    \n","    cls_tokens = self.cls_token.expand(B, -1, -1)\n","    dist_token = self.dist_token.expand(B, -1, -1)\n","\n","    x = torch.cat((cls_tokens, dist_token, x), dim=1)\n","    x = x + self.pos_embed\n","    x = self.pos_drop(x)\n","\n","    x = self.blocks(x)\n","    x = self.norm(x)\n","\n","    x = (x[:, 0] + x[:, 1]) / 2\n","    x = self.fc_norm(x)\n","    x = self.head(x)\n","    return x\n","     \n"]},{"cell_type":"markdown","metadata":{"id":"Br0IVv-7DPHf"},"source":["## CIFAR 10"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1342,"status":"ok","timestamp":1686155218494,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"iYbFejY8Wb77","outputId":"b56fd4d6-8e2a-48a8-a667-7c8b38cc4937"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.load:Using the latest cached version of the module from /root/.cache/huggingface/modules/datasets_modules/datasets/cifar10/447d6ec4733dddd1ce3bb577c7166b986eaa4c538dcd9e805ba61f35674a9de4 (last modified on Wed Jun  7 14:03:23 2023) since it couldn't be found locally at cifar10., or remotely on the Hugging Face Hub.\n"]}],"source":["from datasets import load_dataset, Image\n","dset = load_dataset('cifar10', split='train', streaming=True).cast_column(\"image\", Image())\n","dset_test = load_dataset('cifar10', split='test', streaming=True, use_auth_token=True).cast_column(\"image\", Image())\n"]},{"cell_type":"code","execution_count":39,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686155218494,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"NZ0cvoINRPMa"},"outputs":[],"source":["#CIFAR10 on huggingface doesn't have eval set\n","\n","dset = dset.map(transforms_, batched=True)\n","dset_test = dset_test.map(transforms_, batched=True)\n","\n","dset_iter = dset.with_format(\"torch\")\n","dset_test_iter = dset_test.with_format(\"torch\")"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1686574034917,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"S0PJCNJZC2gM"},"outputs":[],"source":["# class Arguments():\n","#   bal=None\n","#   lr=2.5e-4\n","#   mixup=0.6\n","#   noise=True\n","#   num_workers = 32\n","#   optimizer = 'adam'\n","#   metrics='acc'\n","#   loss='BCE'              \n","#   lrscheduler_start=5\n","#   lrscheduler_step=1\n","#   lrscheduler_decay=0.85\n","#   warmup = False\n","#   wa = False\n","#   wa_start = 1\n","#   wa_end = 5\n","#   lr_patience = 2\n","#   save_model = True\n","\n","args_pretraining = Arguments()\n","args_pretraining.exp_dir = '/content/drive/MyDrive/Thesis/pretrain_qvit_CIFAR10'\n","args_pretraining.n_classes = 10\n","args_pretraining.img_size = 128\n","\n","args_pretraining.batch_size = 128\n","args_pretraining.n_epochs = 30\n","args_pretraining.lr = 2.5e-4\n","args_pretraining.warmup = False\n","\n","# args_pretraining.n_print_steps = 100\n","# args_pretraining.dataset_mean = 0\n","# args_pretraining.dataset_std = 0\n","# args_pretraining.num_workers = 8\n","args_pretraining.mixup = 0.6\n","# args_pretraining.wa = True\n","# args_pretraining.lrscheduler_start=0\n","# args_pretraining.lrscheduler_step=1\n","# args_pretraining.lrscheduler_decay=0.85"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":18456,"status":"ok","timestamp":1686155248665,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"mTLrCJ3Z--jY"},"outputs":[],"source":["ast_mdl_not_pretrained = QVIT(label_dim=args_pretraining.n_classes, img_size = args_pretraining.img_size)"]},{"cell_type":"code","execution_count":43,"metadata":{"executionInfo":{"elapsed":19,"status":"ok","timestamp":1686155248665,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"HvmHVOVkQkpY"},"outputs":[],"source":["train_loader_cifar10 = DataLoader(dset_iter, collate_fn=collate_fn, batch_size = args_pretraining.batch_size, pin_memory=True)\n","test_loader_cifar10 = DataLoader(dset_test_iter, collate_fn=collate_fn, batch_size=args_pretraining.batch_size, pin_memory=True)\n"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1686155248665,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"gZwpJ9LiJKX7","outputId":"c45a80a1-2920-4837-d586-30909daabc2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Folders already exists\n","Target.csv already exists\n"]}],"source":["prepare_result_saving(args_pretraining, val_data = test_loader_cifar10)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1686155248666,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"Rj83GZJi_J91","outputId":"1b57051a-746b-4ec8-9300-40287d916806"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["QVIT(\n","  (patch_embed): PatchEmbedding(\n","    (proj): Conv2d(4, 768, kernel_size=(16, 16), stride=(16, 16))\n","    (norm): Identity()\n","  )\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (blocks): Sequential(\n","    (0): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=69)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=388)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=548)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1042)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (1): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=780)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=879)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=343)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=793)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (2): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=295)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=538)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=272)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=449)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (3): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=442)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=676)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=116)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1022)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (4): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1114)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=974)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=163)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=858)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (5): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=736)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=987)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=437)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=916)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (6): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1114)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=20)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=755)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=165)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (7): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1206)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=912)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=908)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=885)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (8): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=927)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=422)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=555)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1233)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (9): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1162)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=799)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=457)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1130)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (10): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=366)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=147)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=287)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=635)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (11): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=493)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=462)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=400)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=8)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (norm): Norm()\n","  (fc_norm): Norm()\n","  (head): Linear(in_features=768, out_features=10, bias=True)\n",")"]},"metadata":{},"execution_count":45}],"source":["ast_mdl_not_pretrained.to(device)"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7662625,"status":"ok","timestamp":1686162954354,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"v1Vnlmz6lySE","outputId":"11a28137-c01c-4184-b0a0-2885fe8d88a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Now starting training for 30 epochs\n","running on cuda\n","Total parameter number is : 22.174 million\n","Total trainable parameter number is : 22.174 million\n","now training with speechcommands, main metrics: acc, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7fadf153e380>\n","The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n","current #steps=0, #epochs=1\n","start training...\n","---------------\n","2023-06-07 16:28:11.711850\n","current #epochs=1, #steps=0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][100/unk]\tPer Sample Total Time 0.00458\tPer Sample Data Time 0.00144\tPer Sample DNN Time 0.00314\tTrain Loss 0.3309\t\n","Epoch: [1][200/unk]\tPer Sample Total Time 0.00449\tPer Sample Data Time 0.00135\tPer Sample DNN Time 0.00314\tTrain Loss 0.3237\t\n","Epoch: [1][300/unk]\tPer Sample Total Time 0.00443\tPer Sample Data Time 0.00129\tPer Sample DNN Time 0.00314\tTrain Loss 0.3169\t\n","start validation\n","acc: 0.250300\n","AUC: 0.728984\n","Avg Precision: 0.189392\n","Avg Recall: 0.588300\n","d_prime: 0.862307\n","train_loss: 0.312160\n","valid_loss: 0.730730\n","validation finished\n","Epoch-1 lr: 0.00025\n","epoch 1 training time: 253.772\n","---------------\n","2023-06-07 16:32:25.484586\n","current #epochs=2, #steps=391\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][9/unk]\tPer Sample Total Time 0.00626\tPer Sample Data Time 0.00310\tPer Sample DNN Time 0.00316\tTrain Loss 0.2963\t\n","Epoch: [2][109/unk]\tPer Sample Total Time 0.00459\tPer Sample Data Time 0.00145\tPer Sample DNN Time 0.00314\tTrain Loss 0.2912\t\n","Epoch: [2][209/unk]\tPer Sample Total Time 0.00442\tPer Sample Data Time 0.00129\tPer Sample DNN Time 0.00314\tTrain Loss 0.2907\t\n","Epoch: [2][309/unk]\tPer Sample Total Time 0.00442\tPer Sample Data Time 0.00128\tPer Sample DNN Time 0.00314\tTrain Loss 0.2886\t\n","start validation\n","acc: 0.312300\n","AUC: 0.780988\n","Avg Precision: 0.190658\n","Avg Recall: 0.798900\n","d_prime: 1.096770\n","train_loss: 0.286902\n","valid_loss: 0.726345\n","validation finished\n","Epoch-2 lr: 0.00025\n","epoch 2 training time: 252.541\n","---------------\n","2023-06-07 16:36:38.025529\n","current #epochs=3, #steps=782\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][18/unk]\tPer Sample Total Time 0.00530\tPer Sample Data Time 0.00216\tPer Sample DNN Time 0.00314\tTrain Loss 0.2797\t\n","Epoch: [3][118/unk]\tPer Sample Total Time 0.00455\tPer Sample Data Time 0.00141\tPer Sample DNN Time 0.00314\tTrain Loss 0.2768\t\n","Epoch: [3][218/unk]\tPer Sample Total Time 0.00443\tPer Sample Data Time 0.00130\tPer Sample DNN Time 0.00314\tTrain Loss 0.2765\t\n","Epoch: [3][318/unk]\tPer Sample Total Time 0.00445\tPer Sample Data Time 0.00131\tPer Sample DNN Time 0.00314\tTrain Loss 0.2743\t\n","start validation\n","acc: 0.340800\n","AUC: 0.815974\n","Avg Precision: 0.193000\n","Avg Recall: 0.883700\n","d_prime: 1.272975\n","train_loss: 0.273018\n","valid_loss: 0.723418\n","validation finished\n","Epoch-3 lr: 0.00025\n","epoch 3 training time: 253.162\n","---------------\n","2023-06-07 16:40:51.187344\n","current #epochs=4, #steps=1173\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][27/unk]\tPer Sample Total Time 0.00512\tPer Sample Data Time 0.00192\tPer Sample DNN Time 0.00320\tTrain Loss 0.2671\t\n","Epoch: [4][127/unk]\tPer Sample Total Time 0.00457\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.00315\tTrain Loss 0.2611\t\n","Epoch: [4][227/unk]\tPer Sample Total Time 0.00445\tPer Sample Data Time 0.00131\tPer Sample DNN Time 0.00314\tTrain Loss 0.2596\t\n","Epoch: [4][327/unk]\tPer Sample Total Time 0.00444\tPer Sample Data Time 0.00130\tPer Sample DNN Time 0.00314\tTrain Loss 0.2567\t\n","start validation\n","acc: 0.382900\n","AUC: 0.846799\n","Avg Precision: 0.251329\n","Avg Recall: 0.845100\n","d_prime: 1.446461\n","train_loss: 0.255825\n","valid_loss: 0.718725\n","validation finished\n","Epoch-4 lr: 0.00025\n","epoch 4 training time: 253.034\n","---------------\n","2023-06-07 16:45:04.222408\n","current #epochs=5, #steps=1564\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [5][36/unk]\tPer Sample Total Time 0.00463\tPer Sample Data Time 0.00149\tPer Sample DNN Time 0.00314\tTrain Loss 0.2470\t\n","Epoch: [5][136/unk]\tPer Sample Total Time 0.00447\tPer Sample Data Time 0.00133\tPer Sample DNN Time 0.00314\tTrain Loss 0.2469\t\n","Epoch: [5][236/unk]\tPer Sample Total Time 0.00447\tPer Sample Data Time 0.00133\tPer Sample DNN Time 0.00314\tTrain Loss 0.2460\t\n","Epoch: [5][336/unk]\tPer Sample Total Time 0.00442\tPer Sample Data Time 0.00128\tPer Sample DNN Time 0.00314\tTrain Loss 0.2436\t\n","start validation\n","acc: 0.437100\n","AUC: 0.866172\n","Avg Precision: 0.264803\n","Avg Recall: 0.847100\n","d_prime: 1.567621\n","train_loss: 0.242411\n","valid_loss: 0.716060\n","validation finished\n","Epoch-5 lr: 0.0002125\n","epoch 5 training time: 251.276\n","---------------\n","2023-06-07 16:49:15.498457\n","current #epochs=6, #steps=1955\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [6][45/unk]\tPer Sample Total Time 0.00451\tPer Sample Data Time 0.00137\tPer Sample DNN Time 0.00313\tTrain Loss 0.2328\t\n","Epoch: [6][145/unk]\tPer Sample Total Time 0.00444\tPer Sample Data Time 0.00130\tPer Sample DNN Time 0.00314\tTrain Loss 0.2313\t\n","Epoch: [6][245/unk]\tPer Sample Total Time 0.00448\tPer Sample Data Time 0.00135\tPer Sample DNN Time 0.00314\tTrain Loss 0.2296\t\n","Epoch: [6][345/unk]\tPer Sample Total Time 0.00446\tPer Sample Data Time 0.00133\tPer Sample DNN Time 0.00314\tTrain Loss 0.2278\t\n","start validation\n","acc: 0.482300\n","AUC: 0.884143\n","Avg Precision: 0.366739\n","Avg Recall: 0.724000\n","d_prime: 1.691340\n","train_loss: 0.226907\n","valid_loss: 0.711885\n","validation finished\n","Epoch-6 lr: 0.00018062499999999999\n","epoch 6 training time: 254.670\n","---------------\n","2023-06-07 16:53:30.168968\n","current #epochs=7, #steps=2346\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [7][54/unk]\tPer Sample Total Time 0.00455\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.00313\tTrain Loss 0.2174\t\n","Epoch: [7][154/unk]\tPer Sample Total Time 0.00443\tPer Sample Data Time 0.00129\tPer Sample DNN Time 0.00314\tTrain Loss 0.2160\t\n","Epoch: [7][254/unk]\tPer Sample Total Time 0.00446\tPer Sample Data Time 0.00132\tPer Sample DNN Time 0.00314\tTrain Loss 0.2151\t\n","Epoch: [7][354/unk]\tPer Sample Total Time 0.00441\tPer Sample Data Time 0.00128\tPer Sample DNN Time 0.00314\tTrain Loss 0.2136\t\n","start validation\n","acc: 0.506100\n","AUC: 0.895101\n","Avg Precision: 0.346144\n","Avg Recall: 0.791000\n","d_prime: 1.773597\n","train_loss: 0.212887\n","valid_loss: 0.710876\n","validation finished\n","Epoch-7 lr: 0.00015353125\n","epoch 7 training time: 252.929\n","---------------\n","2023-06-07 16:57:43.098568\n","current #epochs=8, #steps=2737\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [8][63/unk]\tPer Sample Total Time 0.00448\tPer Sample Data Time 0.00135\tPer Sample DNN Time 0.00313\tTrain Loss 0.2077\t\n","Epoch: [8][163/unk]\tPer Sample Total Time 0.00447\tPer Sample Data Time 0.00134\tPer Sample DNN Time 0.00313\tTrain Loss 0.2035\t\n","Epoch: [8][263/unk]\tPer Sample Total Time 0.00444\tPer Sample Data Time 0.00131\tPer Sample DNN Time 0.00313\tTrain Loss 0.2046\t\n","Epoch: [8][363/unk]\tPer Sample Total Time 0.00443\tPer Sample Data Time 0.00130\tPer Sample DNN Time 0.00313\tTrain Loss 0.2026\t\n","start validation\n","acc: 0.538500\n","AUC: 0.905268\n","Avg Precision: 0.393661\n","Avg Recall: 0.790100\n","d_prime: 1.855680\n","train_loss: 0.202098\n","valid_loss: 0.707527\n","validation finished\n","Epoch-8 lr: 0.0001305015625\n","epoch 8 training time: 258.104\n","---------------\n","2023-06-07 17:02:01.203141\n","current #epochs=9, #steps=3128\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [9][72/unk]\tPer Sample Total Time 0.00479\tPer Sample Data Time 0.00165\tPer Sample DNN Time 0.00313\tTrain Loss 0.1968\t\n","Epoch: [9][172/unk]\tPer Sample Total Time 0.00474\tPer Sample Data Time 0.00161\tPer Sample DNN Time 0.00313\tTrain Loss 0.1936\t\n","Epoch: [9][272/unk]\tPer Sample Total Time 0.00457\tPer Sample Data Time 0.00143\tPer Sample DNN Time 0.00313\tTrain Loss 0.1943\t\n","Epoch: [9][372/unk]\tPer Sample Total Time 0.00449\tPer Sample Data Time 0.00136\tPer Sample DNN Time 0.00313\tTrain Loss 0.1925\t\n","start validation\n","acc: 0.553000\n","AUC: 0.911129\n","Avg Precision: 0.403010\n","Avg Recall: 0.800700\n","d_prime: 1.905995\n","train_loss: 0.192287\n","valid_loss: 0.705328\n","validation finished\n","Epoch-9 lr: 0.00011092632812499999\n","epoch 9 training time: 257.577\n","---------------\n","2023-06-07 17:06:18.780108\n","current #epochs=10, #steps=3519\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [10][81/unk]\tPer Sample Total Time 0.00476\tPer Sample Data Time 0.00163\tPer Sample DNN Time 0.00313\tTrain Loss 0.1899\t\n","Epoch: [10][181/unk]\tPer Sample Total Time 0.00449\tPer Sample Data Time 0.00136\tPer Sample DNN Time 0.00313\tTrain Loss 0.1862\t\n","Epoch: [10][281/unk]\tPer Sample Total Time 0.00442\tPer Sample Data Time 0.00129\tPer Sample DNN Time 0.00313\tTrain Loss 0.1857\t\n","Epoch: [10][381/unk]\tPer Sample Total Time 0.00439\tPer Sample Data Time 0.00126\tPer Sample DNN Time 0.00313\tTrain Loss 0.1838\t\n","start validation\n","acc: 0.566500\n","AUC: 0.916452\n","Avg Precision: 0.402657\n","Avg Recall: 0.817700\n","d_prime: 1.953871\n","train_loss: 0.183753\n","valid_loss: 0.705096\n","validation finished\n","Epoch-10 lr: 9.428737890624999e-05\n","epoch 10 training time: 254.011\n","---------------\n","2023-06-07 17:10:32.790915\n","current #epochs=11, #steps=3910\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [11][90/unk]\tPer Sample Total Time 0.00472\tPer Sample Data Time 0.00158\tPer Sample DNN Time 0.00314\tTrain Loss 0.1808\t\n","Epoch: [11][190/unk]\tPer Sample Total Time 0.00449\tPer Sample Data Time 0.00136\tPer Sample DNN Time 0.00313\tTrain Loss 0.1789\t\n","Epoch: [11][290/unk]\tPer Sample Total Time 0.00444\tPer Sample Data Time 0.00131\tPer Sample DNN Time 0.00313\tTrain Loss 0.1783\t\n","Epoch: [11][390/unk]\tPer Sample Total Time 0.00439\tPer Sample Data Time 0.00126\tPer Sample DNN Time 0.00313\tTrain Loss 0.1765\t\n","start validation\n","acc: 0.572600\n","AUC: 0.919337\n","Avg Precision: 0.430325\n","Avg Recall: 0.795800\n","d_prime: 1.980787\n","train_loss: 0.176456\n","valid_loss: 0.702602\n","validation finished\n","Epoch-11 lr: 8.014427207031248e-05\n","epoch 11 training time: 252.860\n","---------------\n","2023-06-07 17:14:45.650641\n","current #epochs=12, #steps=4301\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [12][99/unk]\tPer Sample Total Time 0.00472\tPer Sample Data Time 0.00158\tPer Sample DNN Time 0.00314\tTrain Loss 0.1746\t\n","Epoch: [12][199/unk]\tPer Sample Total Time 0.00451\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.00313\tTrain Loss 0.1726\t\n","Epoch: [12][299/unk]\tPer Sample Total Time 0.00445\tPer Sample Data Time 0.00132\tPer Sample DNN Time 0.00313\tTrain Loss 0.1719\t\n","start validation\n","acc: 0.583500\n","AUC: 0.921336\n","Avg Precision: 0.375038\n","Avg Recall: 0.863600\n","d_prime: 1.999857\n","train_loss: 0.170303\n","valid_loss: 0.701608\n","validation finished\n","Epoch-12 lr: 6.81226312597656e-05\n","epoch 12 training time: 253.111\n","---------------\n","2023-06-07 17:18:58.761469\n","current #epochs=13, #steps=4692\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [13][8/unk]\tPer Sample Total Time 0.00637\tPer Sample Data Time 0.00324\tPer Sample DNN Time 0.00314\tTrain Loss 0.1723\t\n","Epoch: [13][108/unk]\tPer Sample Total Time 0.00453\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.00315\tTrain Loss 0.1692\t\n","Epoch: [13][208/unk]\tPer Sample Total Time 0.00443\tPer Sample Data Time 0.00129\tPer Sample DNN Time 0.00314\tTrain Loss 0.1670\t\n","Epoch: [13][308/unk]\tPer Sample Total Time 0.00442\tPer Sample Data Time 0.00128\tPer Sample DNN Time 0.00314\tTrain Loss 0.1662\t\n","start validation\n","acc: 0.587700\n","AUC: 0.922805\n","Avg Precision: 0.386108\n","Avg Recall: 0.839200\n","d_prime: 2.014120\n","train_loss: 0.165159\n","valid_loss: 0.701781\n","validation finished\n","Epoch-13 lr: 5.7904236570800764e-05\n","epoch 13 training time: 252.616\n","---------------\n","2023-06-07 17:23:11.376896\n","current #epochs=14, #steps=5083\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [14][17/unk]\tPer Sample Total Time 0.00532\tPer Sample Data Time 0.00217\tPer Sample DNN Time 0.00315\tTrain Loss 0.1647\t\n","Epoch: [14][117/unk]\tPer Sample Total Time 0.00456\tPer Sample Data Time 0.00143\tPer Sample DNN Time 0.00314\tTrain Loss 0.1634\t\n","Epoch: [14][217/unk]\tPer Sample Total Time 0.00442\tPer Sample Data Time 0.00129\tPer Sample DNN Time 0.00314\tTrain Loss 0.1613\t\n","Epoch: [14][317/unk]\tPer Sample Total Time 0.00444\tPer Sample Data Time 0.00130\tPer Sample DNN Time 0.00314\tTrain Loss 0.1602\t\n","start validation\n","acc: 0.602000\n","AUC: 0.927483\n","Avg Precision: 0.428039\n","Avg Recall: 0.831000\n","d_prime: 2.060927\n","train_loss: 0.159385\n","valid_loss: 0.700826\n","validation finished\n","Epoch-14 lr: 4.921860108518065e-05\n","epoch 14 training time: 252.269\n","---------------\n","2023-06-07 17:27:23.645861\n","current #epochs=15, #steps=5474\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [15][26/unk]\tPer Sample Total Time 0.00557\tPer Sample Data Time 0.00242\tPer Sample DNN Time 0.00314\tTrain Loss 0.1601\t\n","Epoch: [15][126/unk]\tPer Sample Total Time 0.00465\tPer Sample Data Time 0.00152\tPer Sample DNN Time 0.00314\tTrain Loss 0.1563\t\n","Epoch: [15][226/unk]\tPer Sample Total Time 0.00454\tPer Sample Data Time 0.00140\tPer Sample DNN Time 0.00314\tTrain Loss 0.1551\t\n","Epoch: [15][326/unk]\tPer Sample Total Time 0.00452\tPer Sample Data Time 0.00139\tPer Sample DNN Time 0.00314\tTrain Loss 0.1542\t\n","start validation\n","acc: 0.611400\n","AUC: 0.929837\n","Avg Precision: 0.407603\n","Avg Recall: 0.846500\n","d_prime: 2.085365\n","train_loss: 0.153700\n","valid_loss: 0.699597\n","validation finished\n","Epoch-15 lr: 4.183581092240355e-05\n","epoch 15 training time: 255.976\n","---------------\n","2023-06-07 17:31:39.621716\n","current #epochs=16, #steps=5865\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [16][35/unk]\tPer Sample Total Time 0.00474\tPer Sample Data Time 0.00160\tPer Sample DNN Time 0.00314\tTrain Loss 0.1541\t\n","Epoch: [16][135/unk]\tPer Sample Total Time 0.00450\tPer Sample Data Time 0.00136\tPer Sample DNN Time 0.00314\tTrain Loss 0.1515\t\n","Epoch: [16][235/unk]\tPer Sample Total Time 0.00452\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.00314\tTrain Loss 0.1507\t\n","Epoch: [16][335/unk]\tPer Sample Total Time 0.00446\tPer Sample Data Time 0.00132\tPer Sample DNN Time 0.00314\tTrain Loss 0.1491\t\n","start validation\n","acc: 0.611400\n","AUC: 0.931446\n","Avg Precision: 0.415763\n","Avg Recall: 0.849600\n","d_prime: 2.102432\n","train_loss: 0.148882\n","valid_loss: 0.699060\n","validation finished\n","Epoch-16 lr: 3.556043928404302e-05\n","epoch 16 training time: 252.200\n","---------------\n","2023-06-07 17:35:51.821905\n","current #epochs=17, #steps=6256\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [17][44/unk]\tPer Sample Total Time 0.00449\tPer Sample Data Time 0.00135\tPer Sample DNN Time 0.00313\tTrain Loss 0.1485\t\n","Epoch: [17][144/unk]\tPer Sample Total Time 0.00448\tPer Sample Data Time 0.00133\tPer Sample DNN Time 0.00315\tTrain Loss 0.1466\t\n","Epoch: [17][244/unk]\tPer Sample Total Time 0.00447\tPer Sample Data Time 0.00133\tPer Sample DNN Time 0.00315\tTrain Loss 0.1464\t\n","Epoch: [17][344/unk]\tPer Sample Total Time 0.00442\tPer Sample Data Time 0.00128\tPer Sample DNN Time 0.00314\tTrain Loss 0.1445\t\n","start validation\n","acc: 0.613400\n","AUC: 0.931907\n","Avg Precision: 0.422195\n","Avg Recall: 0.845100\n","d_prime: 2.107384\n","train_loss: 0.144416\n","valid_loss: 0.698318\n","validation finished\n","Epoch-17 lr: 3.0226373391436563e-05\n","epoch 17 training time: 252.001\n","---------------\n","2023-06-07 17:40:03.823230\n","current #epochs=18, #steps=6647\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [18][53/unk]\tPer Sample Total Time 0.00446\tPer Sample Data Time 0.00129\tPer Sample DNN Time 0.00316\tTrain Loss 0.1453\t\n","Epoch: [18][153/unk]\tPer Sample Total Time 0.00447\tPer Sample Data Time 0.00132\tPer Sample DNN Time 0.00315\tTrain Loss 0.1426\t\n","Epoch: [18][253/unk]\tPer Sample Total Time 0.00445\tPer Sample Data Time 0.00131\tPer Sample DNN Time 0.00314\tTrain Loss 0.1425\t\n","Epoch: [18][353/unk]\tPer Sample Total Time 0.00442\tPer Sample Data Time 0.00127\tPer Sample DNN Time 0.00315\tTrain Loss 0.1405\t\n","start validation\n","acc: 0.616500\n","AUC: 0.932152\n","Avg Precision: 0.393802\n","Avg Recall: 0.847400\n","d_prime: 2.110023\n","train_loss: 0.140430\n","valid_loss: 0.697574\n","validation finished\n","Epoch-18 lr: 2.5692417382721078e-05\n","epoch 18 training time: 251.491\n","---------------\n","2023-06-07 17:44:15.314781\n","current #epochs=19, #steps=7038\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [19][62/unk]\tPer Sample Total Time 0.00465\tPer Sample Data Time 0.00151\tPer Sample DNN Time 0.00314\tTrain Loss 0.1430\t\n","Epoch: [19][162/unk]\tPer Sample Total Time 0.00460\tPer Sample Data Time 0.00146\tPer Sample DNN Time 0.00313\tTrain Loss 0.1391\t\n","Epoch: [19][262/unk]\tPer Sample Total Time 0.00449\tPer Sample Data Time 0.00136\tPer Sample DNN Time 0.00314\tTrain Loss 0.1388\t\n","Epoch: [19][362/unk]\tPer Sample Total Time 0.00449\tPer Sample Data Time 0.00135\tPer Sample DNN Time 0.00314\tTrain Loss 0.1366\t\n","start validation\n","acc: 0.618300\n","AUC: 0.932451\n","Avg Precision: 0.433254\n","Avg Recall: 0.831000\n","d_prime: 2.113254\n","train_loss: 0.136793\n","valid_loss: 0.697045\n","validation finished\n","Epoch-19 lr: 2.1838554775312915e-05\n","epoch 19 training time: 256.937\n","---------------\n","2023-06-07 17:48:32.251568\n","current #epochs=20, #steps=7429\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [20][71/unk]\tPer Sample Total Time 0.00448\tPer Sample Data Time 0.00135\tPer Sample DNN Time 0.00314\tTrain Loss 0.1397\t\n","Epoch: [20][171/unk]\tPer Sample Total Time 0.00479\tPer Sample Data Time 0.00165\tPer Sample DNN Time 0.00314\tTrain Loss 0.1356\t\n","Epoch: [20][271/unk]\tPer Sample Total Time 0.00463\tPer Sample Data Time 0.00149\tPer Sample DNN Time 0.00314\tTrain Loss 0.1353\t\n","Epoch: [20][371/unk]\tPer Sample Total Time 0.00457\tPer Sample Data Time 0.00143\tPer Sample DNN Time 0.00314\tTrain Loss 0.1332\t\n","start validation\n","acc: 0.616100\n","AUC: 0.932713\n","Avg Precision: 0.432903\n","Avg Recall: 0.830800\n","d_prime: 2.116094\n","train_loss: 0.133415\n","valid_loss: 0.696631\n","validation finished\n","Epoch-20 lr: 1.8562771559015977e-05\n","epoch 20 training time: 259.730\n","---------------\n","2023-06-07 17:52:51.981886\n","current #epochs=21, #steps=7820\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [21][80/unk]\tPer Sample Total Time 0.00471\tPer Sample Data Time 0.00155\tPer Sample DNN Time 0.00316\tTrain Loss 0.1370\t\n","Epoch: [21][180/unk]\tPer Sample Total Time 0.00453\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.00315\tTrain Loss 0.1324\t\n","Epoch: [21][280/unk]\tPer Sample Total Time 0.00446\tPer Sample Data Time 0.00132\tPer Sample DNN Time 0.00314\tTrain Loss 0.1321\t\n","Epoch: [21][380/unk]\tPer Sample Total Time 0.00443\tPer Sample Data Time 0.00128\tPer Sample DNN Time 0.00314\tTrain Loss 0.1306\t\n","start validation\n","acc: 0.620900\n","AUC: 0.933007\n","Avg Precision: 0.429911\n","Avg Recall: 0.836000\n","d_prime: 2.119291\n","train_loss: 0.130554\n","valid_loss: 0.696404\n","validation finished\n","Epoch-21 lr: 1.577835582516358e-05\n","epoch 21 training time: 261.488\n","---------------\n","2023-06-07 17:57:13.469795\n","current #epochs=22, #steps=8211\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [22][89/unk]\tPer Sample Total Time 0.00474\tPer Sample Data Time 0.00160\tPer Sample DNN Time 0.00314\tTrain Loss 0.1337\t\n","Epoch: [22][189/unk]\tPer Sample Total Time 0.00452\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.00314\tTrain Loss 0.1294\t\n","Epoch: [22][289/unk]\tPer Sample Total Time 0.00449\tPer Sample Data Time 0.00135\tPer Sample DNN Time 0.00314\tTrain Loss 0.1292\t\n","Epoch: [22][389/unk]\tPer Sample Total Time 0.00442\tPer Sample Data Time 0.00129\tPer Sample DNN Time 0.00314\tTrain Loss 0.1278\t\n","start validation\n","acc: 0.625900\n","AUC: 0.933636\n","Avg Precision: 0.405979\n","Avg Recall: 0.842000\n","d_prime: 2.126170\n","train_loss: 0.127798\n","valid_loss: 0.696135\n","validation finished\n","Epoch-22 lr: 1.3411602451389044e-05\n","epoch 22 training time: 258.831\n","---------------\n","2023-06-07 18:01:32.301134\n","current #epochs=23, #steps=8602\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [23][98/unk]\tPer Sample Total Time 0.00460\tPer Sample Data Time 0.00146\tPer Sample DNN Time 0.00314\tTrain Loss 0.1311\t\n","Epoch: [23][198/unk]\tPer Sample Total Time 0.00447\tPer Sample Data Time 0.00133\tPer Sample DNN Time 0.00314\tTrain Loss 0.1271\t\n","Epoch: [23][298/unk]\tPer Sample Total Time 0.00445\tPer Sample Data Time 0.00132\tPer Sample DNN Time 0.00314\tTrain Loss 0.1269\t\n","start validation\n","acc: 0.627300\n","AUC: 0.934417\n","Avg Precision: 0.325709\n","Avg Recall: 0.886900\n","d_prime: 2.134783\n","train_loss: 0.125381\n","valid_loss: 0.695727\n","validation finished\n","Epoch-23 lr: 1.1399862083680687e-05\n","epoch 23 training time: 256.039\n","---------------\n","2023-06-07 18:05:48.340356\n","current #epochs=24, #steps=8993\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [24][7/unk]\tPer Sample Total Time 0.00672\tPer Sample Data Time 0.00358\tPer Sample DNN Time 0.00314\tTrain Loss 0.1329\t\n","Epoch: [24][107/unk]\tPer Sample Total Time 0.00472\tPer Sample Data Time 0.00158\tPer Sample DNN Time 0.00314\tTrain Loss 0.1278\t\n","Epoch: [24][207/unk]\tPer Sample Total Time 0.00453\tPer Sample Data Time 0.00139\tPer Sample DNN Time 0.00314\tTrain Loss 0.1252\t\n","Epoch: [24][307/unk]\tPer Sample Total Time 0.00453\tPer Sample Data Time 0.00139\tPer Sample DNN Time 0.00314\tTrain Loss 0.1245\t\n","start validation\n","acc: 0.626400\n","AUC: 0.934417\n","Avg Precision: 0.329538\n","Avg Recall: 0.889500\n","d_prime: 2.134784\n","train_loss: 0.123200\n","valid_loss: 0.695838\n","validation finished\n","Epoch-24 lr: 9.689882771128584e-06\n","epoch 24 training time: 257.182\n","---------------\n","2023-06-07 18:10:05.522208\n","current #epochs=25, #steps=9384\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [25][16/unk]\tPer Sample Total Time 0.00543\tPer Sample Data Time 0.00230\tPer Sample DNN Time 0.00313\tTrain Loss 0.1302\t\n","Epoch: [25][116/unk]\tPer Sample Total Time 0.00452\tPer Sample Data Time 0.00139\tPer Sample DNN Time 0.00314\tTrain Loss 0.1254\t\n","Epoch: [25][216/unk]\tPer Sample Total Time 0.00450\tPer Sample Data Time 0.00137\tPer Sample DNN Time 0.00314\tTrain Loss 0.1230\t\n","Epoch: [25][316/unk]\tPer Sample Total Time 0.00452\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.00314\tTrain Loss 0.1221\t\n","start validation\n","acc: 0.628900\n","AUC: 0.934704\n","Avg Precision: 0.331861\n","Avg Recall: 0.892500\n","d_prime: 2.137972\n","train_loss: 0.121254\n","valid_loss: 0.695843\n","validation finished\n","Epoch-25 lr: 8.236400355459297e-06\n","epoch 25 training time: 257.098\n","---------------\n","2023-06-07 18:14:22.620442\n","current #epochs=26, #steps=9775\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [26][25/unk]\tPer Sample Total Time 0.00497\tPer Sample Data Time 0.00183\tPer Sample DNN Time 0.00314\tTrain Loss 0.1281\t\n","Epoch: [26][125/unk]\tPer Sample Total Time 0.00451\tPer Sample Data Time 0.00137\tPer Sample DNN Time 0.00315\tTrain Loss 0.1234\t\n","Epoch: [26][225/unk]\tPer Sample Total Time 0.00439\tPer Sample Data Time 0.00125\tPer Sample DNN Time 0.00315\tTrain Loss 0.1213\t\n","Epoch: [26][325/unk]\tPer Sample Total Time 0.00446\tPer Sample Data Time 0.00131\tPer Sample DNN Time 0.00315\tTrain Loss 0.1200\t\n","start validation\n","acc: 0.630600\n","AUC: 0.934921\n","Avg Precision: 0.336842\n","Avg Recall: 0.889100\n","d_prime: 2.140382\n","train_loss: 0.119476\n","valid_loss: 0.695642\n","validation finished\n","Epoch-26 lr: 7.0009403021404025e-06\n","epoch 26 training time: 257.095\n","---------------\n","2023-06-07 18:18:39.715247\n","current #epochs=27, #steps=10166\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [27][34/unk]\tPer Sample Total Time 0.00499\tPer Sample Data Time 0.00185\tPer Sample DNN Time 0.00314\tTrain Loss 0.1246\t\n","Epoch: [27][134/unk]\tPer Sample Total Time 0.00456\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.00314\tTrain Loss 0.1212\t\n","Epoch: [27][234/unk]\tPer Sample Total Time 0.00458\tPer Sample Data Time 0.00144\tPer Sample DNN Time 0.00314\tTrain Loss 0.1195\t\n","Epoch: [27][334/unk]\tPer Sample Total Time 0.00450\tPer Sample Data Time 0.00137\tPer Sample DNN Time 0.00314\tTrain Loss 0.1180\t\n","start validation\n","acc: 0.631600\n","AUC: 0.935198\n","Avg Precision: 0.310545\n","Avg Recall: 0.901700\n","d_prime: 2.143469\n","train_loss: 0.117889\n","valid_loss: 0.695223\n","validation finished\n","Epoch-27 lr: 5.950799256819342e-06\n","epoch 27 training time: 258.854\n","---------------\n","2023-06-07 18:22:58.569181\n","current #epochs=28, #steps=10557\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [28][43/unk]\tPer Sample Total Time 0.00465\tPer Sample Data Time 0.00150\tPer Sample DNN Time 0.00314\tTrain Loss 0.1212\t\n","Epoch: [28][143/unk]\tPer Sample Total Time 0.00452\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.00314\tTrain Loss 0.1194\t\n","Epoch: [28][243/unk]\tPer Sample Total Time 0.00454\tPer Sample Data Time 0.00140\tPer Sample DNN Time 0.00315\tTrain Loss 0.1183\t\n","Epoch: [28][343/unk]\tPer Sample Total Time 0.00450\tPer Sample Data Time 0.00136\tPer Sample DNN Time 0.00314\tTrain Loss 0.1165\t\n","start validation\n","acc: 0.635800\n","AUC: 0.935486\n","Avg Precision: 0.313579\n","Avg Recall: 0.901900\n","d_prime: 2.146698\n","train_loss: 0.116434\n","valid_loss: 0.694807\n","validation finished\n","Epoch-28 lr: 5.058179368296441e-06\n","epoch 28 training time: 259.069\n","---------------\n","2023-06-07 18:27:17.638376\n","current #epochs=29, #steps=10948\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [29][52/unk]\tPer Sample Total Time 0.00456\tPer Sample Data Time 0.00142\tPer Sample DNN Time 0.00314\tTrain Loss 0.1210\t\n","Epoch: [29][152/unk]\tPer Sample Total Time 0.00451\tPer Sample Data Time 0.00137\tPer Sample DNN Time 0.00314\tTrain Loss 0.1177\t\n","Epoch: [29][252/unk]\tPer Sample Total Time 0.00450\tPer Sample Data Time 0.00136\tPer Sample DNN Time 0.00314\tTrain Loss 0.1169\t\n","Epoch: [29][352/unk]\tPer Sample Total Time 0.00448\tPer Sample Data Time 0.00134\tPer Sample DNN Time 0.00314\tTrain Loss 0.1150\t\n","start validation\n","acc: 0.639100\n","AUC: 0.935497\n","Avg Precision: 0.319081\n","Avg Recall: 0.896000\n","d_prime: 2.146828\n","train_loss: 0.115047\n","valid_loss: 0.694355\n","validation finished\n","Epoch-29 lr: 4.299452463051975e-06\n","epoch 29 training time: 257.276\n","---------------\n","2023-06-07 18:31:34.914631\n","current #epochs=30, #steps=11339\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/datasets/features/image.py:325: UserWarning: Downcasting array dtype uint8 to uint8 to be compatible with 'Pillow'\n","  warnings.warn(f\"Downcasting array dtype {dtype} to {dest_dtype} to be compatible with 'Pillow'\")\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [30][61/unk]\tPer Sample Total Time 0.00448\tPer Sample Data Time 0.00134\tPer Sample DNN Time 0.00314\tTrain Loss 0.1213\t\n","Epoch: [30][161/unk]\tPer Sample Total Time 0.00464\tPer Sample Data Time 0.00149\tPer Sample DNN Time 0.00315\tTrain Loss 0.1167\t\n","Epoch: [30][261/unk]\tPer Sample Total Time 0.00456\tPer Sample Data Time 0.00141\tPer Sample DNN Time 0.00314\tTrain Loss 0.1159\t\n","Epoch: [30][361/unk]\tPer Sample Total Time 0.00452\tPer Sample Data Time 0.00138\tPer Sample DNN Time 0.00314\tTrain Loss 0.1137\t\n","start validation\n","acc: 0.638500\n","AUC: 0.935343\n","Avg Precision: 0.322927\n","Avg Recall: 0.891900\n","d_prime: 2.145092\n","train_loss: 0.113858\n","valid_loss: 0.694129\n","validation finished\n","Epoch-30 lr: 3.6545345935941787e-06\n","epoch 30 training time: 259.152\n"]}],"source":["# args_pretraining.lr = 2.5e-4\n","print('Now starting training for {:d} epochs'.format(args_pretraining.n_epochs))\n","from src.traintest_cust import train as train_cust\n","from src.traintest_cust import validate as validate_cust \n","train_cust(ast_mdl_not_pretrained, train_loader_cifar10, test_loader_cifar10, args_pretraining)"]},{"cell_type":"markdown","metadata":{"id":"IA0-4u4oP8H_"},"source":["## CIFAR10 pretrained on audio model"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1686573847306,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"rJLxJ2aQnFOu"},"outputs":[],"source":["class Arguments():\n","\n","  model='ast'\n","  dataset='speechcommands'\n","  imagenetpretrain=True\n","  audiosetpretrain=False\n","\n","  bal=None\n","  lr=2.5e-4\n","\n","  n_epochs=20\n","  freqm=48\n","  timem=48\n","  mixup=0.6\n","  batch_size=32\n","  fstride=10\n","  tstride=10\n","  dataset_mean=-6.845978\n","  dataset_std=5.5654526\n","  audio_length = 128\n","  noise=True\n","\n","  num_workers = 32\n","  exp_dir = '/content/drive/MyDrive/Thesis/resout_qast_with_cifar10'\n","  optimizer = 'adam'\n","  metrics='acc'\n","  loss='BCE'              \n","\n","  lrscheduler_start=5\n","  lrscheduler_step=1\n","  lrscheduler_decay=0.85\n","\n","  warmup = False\n","  wa = False\n","  wa_start = 1\n","  wa_end = 5\n","\n","  n_print_steps = 100\n","  n_class = 35\n","  lr_patience = 2\n","  save_model = True\n","args_usepretrain = Arguments()"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4308,"status":"ok","timestamp":1686573851611,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"D4Ws_lp8o_FL","outputId":"a1b5d10b-3047-4ab4-d28a-5fd55651924b"},"outputs":[{"output_type":"stream","name":"stdout","text":["---------------the train dataloader---------------\n","now using following mask: 48 freq, 48 time\n","now using mix-up with rate 0.600000\n","now process speechcommands\n","use dataset mean -6.846 and std 5.565 to normalize the input.\n","now use noise augmentation\n","number of classes is 35\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["---------------the validation dataloader---------------\n","now using following mask: 0 freq, 0 time\n","now using mix-up with rate 0.000000\n","now process speechcommands\n","use dataset mean -6.846 and std 5.565 to normalize the input.\n","number of classes is 35\n","---------------the validation dataloader---------------\n","now using following mask: 0 freq, 0 time\n","now using mix-up with rate 0.000000\n","now process speechcommands\n","use dataset mean -6.846 and std 5.565 to normalize the input.\n","number of classes is 35\n"]}],"source":["data_train = '/content/drive/MyDrive/Thesis/datafiles/speechcommand_train_data.json'\n","data_val_path ='/content/drive/MyDrive/Thesis/datafiles/speechcommand_valid_data.json'\n","data_eval_path ='/content/drive/MyDrive/Thesis/datafiles/speechcommand_eval_data.json'\n","\n","\n","label_csv = '/content/drive/MyDrive/Thesis/ast/egs/speechcommands/data/speechcommands_class_labels_indices.csv'\n","\n","\n","audio_conf = {'num_mel_bins': 128, 'target_length': args_usepretrain.audio_length, 'freqm': args_usepretrain.freqm, 'timem': args_usepretrain.timem, 'mixup': args.mixup, 'dataset': args.dataset, 'mode':'train', 'mean':args.dataset_mean, 'std':args.dataset_std,\n","                  'noise':args_usepretrain.noise}\n","\n","val_audio_conf = {'num_mel_bins': 128, 'target_length': args.audio_length, 'freqm': 0, 'timem': 0, 'mixup': 0, 'dataset': args.dataset, 'mode':'validation', 'mean':args.dataset_mean, 'std':args.dataset_std, 'noise':False}\n","eval_audio_conf = {'num_mel_bins': 128, 'target_length': args.audio_length, 'freqm': 0, 'timem': 0, 'mixup': 0, 'dataset': args.dataset, 'mode':'evaluation', 'mean':args.dataset_mean, 'std':args.dataset_std, 'noise':False}\n","\n","train_loader = torch.utils.data.DataLoader(\n","            dataloader.AudiosetDataset(data_train, label_csv=label_csv, audio_conf=audio_conf),\n","            batch_size=args_usepretrain.batch_size, shuffle=True, num_workers=args_usepretrain.num_workers, pin_memory=True)\n","\n","eval_loader = torch.utils.data.DataLoader(\n","        dataloader.AudiosetDataset(data_eval_path, label_csv=label_csv, audio_conf=val_audio_conf),\n","        batch_size=args_usepretrain.batch_size*2, shuffle=False, num_workers=args_usepretrain.num_workers, pin_memory=True)\n","\n","val_loader = torch.utils.data.DataLoader(\n","        dataloader.AudiosetDataset(data_val_path, label_csv=label_csv, audio_conf=val_audio_conf),\n","        batch_size=args_usepretrain.batch_size*2, shuffle=False, num_workers=args_usepretrain.num_workers, pin_memory=True)"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1686573864718,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"cuQfsd24Y8n3"},"outputs":[],"source":["import torch\n","best_pretrained_model = '/content/drive/MyDrive/Thesis/pretrain_qvit_CIFAR10/models/best_audio_model.pth'\n","# ast_CIFAR_pretrained.load_state_dict()"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":11103,"status":"ok","timestamp":1686573885183,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"tX4P-7sthDSe"},"outputs":[],"source":["from collections import OrderedDict\n","\"\"\"\n","loaded model has keys with \"module.\" like module.fc1\n","to reuse it, need to rewrite it removing module\n","\"\"\"\n","# def load_new_states()\n","new_state_dict = OrderedDict()\n","state_dict = torch.load(best_pretrained_model)\n","for k, v in state_dict.items():\n","    name = \".\".join(k.split(\".\")[1:]) # remove module. at the beginning\n","    new_state_dict[name] = v "]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17486,"status":"ok","timestamp":1686574063086,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"LSoRlEC6hJFP","outputId":"3b8903b8-7ead-4c9d-c931-31d008af945c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":35}],"source":["# ast_CIFAR_pretrained = QVIT(label_dim=10)\n","ast_CIFAR_pretrained = QVIT(label_dim=args_pretraining.n_classes, img_size = args_pretraining.img_size)\n","ast_CIFAR_pretrained.load_state_dict(new_state_dict)"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1686574066063,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"mafo8LVAT_Km"},"outputs":[],"source":["class ASTModel_with_pretraining(nn.Module):\n","  def __init__(self, label_dim=527, fstride=10, tstride=10, input_fdim=128, input_tdim=1024, imagenet_pretrain=True, audioset_pretrain=False, model_size='base384', verbose=True):\n","    super(ASTModel_with_pretraining, self).__init__()\n","    # automatcially get the intermediate shape\n","    self.original_embedding_dim = 768\n","    num_heads = 12\n","    mlp_ratio = 4.\n","    qkv_bias = True\n","    qk_norm = False\n","    drop_rate = 0.\n","    attn_drop_rate = 0.\n","    depth = 12\n","\n","\n","    f_dim, t_dim = self.get_shape(fstride, tstride, input_fdim, input_tdim)\n","    num_patches = f_dim * t_dim\n","\n","    self.patch_embed = PatchEmbed()\n","    self.cls_token = nn.Parameter(torch.zeros(1, 1, self.original_embedding_dim))\n","    self.dist_token = nn.Parameter(torch.zeros(1, 1, self.original_embedding_dim))\n","    self.pos_embed = nn.Parameter(torch.zeros(1, num_patches + 2, self.original_embedding_dim))\n","    trunc_normal_(self.pos_embed, std=.02)\n","    self.pos_drop = nn.Dropout(p=0.)\n","\n","    # TODO pretrained or sinusoidal\n","    if imagenet_pretrain:\n","      self.blocks = ast_CIFAR_pretrained.blocks\n","    else:\n","      self.blocks = nn.Sequential(*[\n","              Block(\n","                  self.original_embedding_dim,\n","                  num_heads,\n","                  mlp_ratio = mlp_ratio,\n","                  qkv_bias = qkv_bias,\n","                  qk_norm = qk_norm,\n","                  drop = drop_rate,\n","                  attn_drop = attn_drop_rate,\n","              )\n","              for i in range(depth)])\n","    self.norm =  Norm(self.original_embedding_dim)\n","\n","    # Classifier Head\n","    self.fc_norm = Norm(self.original_embedding_dim) \n","    self.head = nn.Linear(self.original_embedding_dim, label_dim) if label_dim > 0 else nn.Identity()\n","  \n","  @autocast()\n","  def forward(self, x):\n","    x = x.unsqueeze(1)\n","    x = x.transpose(2, 3)\n","    B = x.shape[0]\n","   \n","    x = self.patch_embed(x)\n","    \n","    cls_tokens = self.cls_token.expand(B, -1, -1)\n","    dist_token = self.dist_token.expand(B, -1, -1)\n","\n","    x = torch.cat((cls_tokens, dist_token, x), dim=1)\n","    x = x + self.pos_embed\n","    x = self.pos_drop(x)\n","\n","    x = self.blocks(x)\n","    x = self.norm(x)\n","\n","    x = (x[:, 0] + x[:, 1]) / 2\n","    x = self.fc_norm(x)\n","    x = self.head(x)\n","    return x\n","     \n","\n","  def get_shape(self, fstride, tstride, input_fdim=128, input_tdim=1024):\n","    test_input = torch.randn(1, 1, input_fdim, input_tdim)\n","    test_proj = nn.Conv2d(1, self.original_embedding_dim, kernel_size=(16, 16), stride=(fstride, tstride))\n","    test_out = test_proj(test_input)\n","    f_dim = test_out.shape[2]\n","    t_dim = test_out.shape[3]\n","    return f_dim, t_dim\n"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":805,"status":"ok","timestamp":1686574071508,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"mEA5LT7zg--o","outputId":"f1ad03c6-d63d-4236-a9af-0f6fb6f1bbaf"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["ASTModel_with_pretraining(\n","  (patch_embed): PatchEmbed(\n","    (projq): QuaternionConv(in_channels=1, out_channels=192, bias=True, kernel_size=(16, 16), stride=10, padding=0, init_criterion=glorot, weight_init=quaternion, seed=808, rotation=False, q_format=True, operation=convolution2d)\n","  )\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (blocks): Sequential(\n","    (0): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=724)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=617)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1041)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1141)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (1): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=833)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=184)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=522)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=963)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (2): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=700)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=841)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=820)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=348)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (3): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1159)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=47)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=900)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=778)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (4): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1168)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1141)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1164)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=760)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (5): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=144)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=472)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1227)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=234)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (6): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1040)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=700)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=908)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=827)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (7): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=304)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=953)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=801)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=177)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (8): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1015)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=831)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=690)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=339)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (9): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=942)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=324)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=498)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=346)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (10): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=783)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=767)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=142)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=71)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (11): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=769)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1200)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=12)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1069)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (norm): Norm()\n","  (fc_norm): Norm()\n","  (head): Linear(in_features=768, out_features=35, bias=True)\n",")"]},"metadata":{},"execution_count":37}],"source":["new_audio_model = ASTModel_with_pretraining(label_dim=args.n_class, fstride=args_usepretrain.fstride, tstride=args_usepretrain.tstride, input_fdim=128,\n","                                input_tdim=args_usepretrain.audio_length, imagenet_pretrain=True,\n","                                audioset_pretrain=args_usepretrain.audiosetpretrain, model_size='base384')\n","new_audio_model.to(device)"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":559,"status":"ok","timestamp":1686574077437,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"WASXHQ8OJX2L","outputId":"8d8b1e48-6a5b-4db3-b32a-6346e368ec2d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Folders already exists\n","Target.csv already exists\n"]}],"source":["prepare_result_saving(args_usepretrain)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fe46N62FftyB","outputId":"55894d4d-f964-4a1a-8b81-65ae31a9798f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Now starting training for 20 epochs\n","running on cuda\n","Total parameter number is : 21.665 million\n","Total trainable parameter number is : 21.665 million\n","now training with speechcommands, main metrics: acc, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f77935561d0>\n","The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n","current #steps=0, #epochs=1\n","start training...\n","---------------\n","2023-06-12 12:48:19.350827\n","current #epochs=1, #steps=0\n","Epoch: [1][100/100000]\tPer Sample Total Time 0.06609\tPer Sample Data Time 0.03517\tPer Sample DNN Time 0.03092\tTrain Loss 0.1747\t\n","Epoch: [1][200/100000]\tPer Sample Total Time 0.04741\tPer Sample Data Time 0.01768\tPer Sample DNN Time 0.02973\tTrain Loss 0.1518\t\n","Epoch: [1][300/100000]\tPer Sample Total Time 0.04114\tPer Sample Data Time 0.01181\tPer Sample DNN Time 0.02933\tTrain Loss 0.1441\t\n","Epoch: [1][400/100000]\tPer Sample Total Time 0.03800\tPer Sample Data Time 0.00887\tPer Sample DNN Time 0.02913\tTrain Loss 0.1402\t\n","Epoch: [1][500/100000]\tPer Sample Total Time 0.03611\tPer Sample Data Time 0.00710\tPer Sample DNN Time 0.02901\tTrain Loss 0.1379\t\n","Epoch: [1][600/100000]\tPer Sample Total Time 0.03557\tPer Sample Data Time 0.00663\tPer Sample DNN Time 0.02894\tTrain Loss 0.1363\t\n","Epoch: [1][700/100000]\tPer Sample Total Time 0.03457\tPer Sample Data Time 0.00569\tPer Sample DNN Time 0.02888\tTrain Loss 0.1352\t\n","Epoch: [1][800/100000]\tPer Sample Total Time 0.03381\tPer Sample Data Time 0.00498\tPer Sample DNN Time 0.02883\tTrain Loss 0.1343\t\n","Epoch: [1][900/100000]\tPer Sample Total Time 0.03322\tPer Sample Data Time 0.00443\tPer Sample DNN Time 0.02879\tTrain Loss 0.1337\t\n","Epoch: [1][1000/100000]\tPer Sample Total Time 0.03275\tPer Sample Data Time 0.00399\tPer Sample DNN Time 0.02876\tTrain Loss 0.1332\t\n","Epoch: [1][1100/100000]\tPer Sample Total Time 0.03236\tPer Sample Data Time 0.00362\tPer Sample DNN Time 0.02874\tTrain Loss 0.1328\t\n","Epoch: [1][1200/100000]\tPer Sample Total Time 0.03204\tPer Sample Data Time 0.00332\tPer Sample DNN Time 0.02872\tTrain Loss 0.1325\t\n","Epoch: [1][1300/100000]\tPer Sample Total Time 0.03177\tPer Sample Data Time 0.00307\tPer Sample DNN Time 0.02870\tTrain Loss 0.1322\t\n","Epoch: [1][1400/100000]\tPer Sample Total Time 0.03154\tPer Sample Data Time 0.00285\tPer Sample DNN Time 0.02869\tTrain Loss 0.1319\t\n","Epoch: [1][1500/100000]\tPer Sample Total Time 0.03134\tPer Sample Data Time 0.00266\tPer Sample DNN Time 0.02867\tTrain Loss 0.1317\t\n","Epoch: [1][1600/100000]\tPer Sample Total Time 0.03116\tPer Sample Data Time 0.00250\tPer Sample DNN Time 0.02866\tTrain Loss 0.1315\t\n","Epoch: [1][1700/100000]\tPer Sample Total Time 0.03100\tPer Sample Data Time 0.00235\tPer Sample DNN Time 0.02865\tTrain Loss 0.1313\t\n","Epoch: [1][1800/100000]\tPer Sample Total Time 0.03086\tPer Sample Data Time 0.00222\tPer Sample DNN Time 0.02864\tTrain Loss 0.1312\t\n","Epoch: [1][1900/100000]\tPer Sample Total Time 0.03073\tPer Sample Data Time 0.00210\tPer Sample DNN Time 0.02863\tTrain Loss 0.1311\t\n","Epoch: [1][2000/100000]\tPer Sample Total Time 0.03062\tPer Sample Data Time 0.00200\tPer Sample DNN Time 0.02862\tTrain Loss 0.1309\t\n","Epoch: [1][2100/100000]\tPer Sample Total Time 0.03052\tPer Sample Data Time 0.00190\tPer Sample DNN Time 0.02862\tTrain Loss 0.1308\t\n","Epoch: [1][2200/100000]\tPer Sample Total Time 0.03043\tPer Sample Data Time 0.00182\tPer Sample DNN Time 0.02861\tTrain Loss 0.1307\t\n","Epoch: [1][2300/100000]\tPer Sample Total Time 0.03034\tPer Sample Data Time 0.00174\tPer Sample DNN Time 0.02860\tTrain Loss 0.1306\t\n","Epoch: [1][2400/100000]\tPer Sample Total Time 0.03027\tPer Sample Data Time 0.00167\tPer Sample DNN Time 0.02860\tTrain Loss 0.1305\t\n","Epoch: [1][2500/100000]\tPer Sample Total Time 0.03019\tPer Sample Data Time 0.00160\tPer Sample DNN Time 0.02859\tTrain Loss 0.1304\t\n","Epoch: [1][2600/100000]\tPer Sample Total Time 0.03013\tPer Sample Data Time 0.00154\tPer Sample DNN Time 0.02859\tTrain Loss 0.1303\t\n","start validation\n","acc: 0.043683\n","AUC: 0.555088\n","Avg Precision: 0.028571\n","Avg Recall: 1.000000\n","d_prime: 0.195905\n","train_loss: 0.130315\n","valid_loss: 0.128587\n","validation finished\n","Epoch-1 lr: 0.00025\n","epoch 1 training time: 2790.279\n","---------------\n","2023-06-12 13:34:49.630689\n","current #epochs=2, #steps=2648\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][52/100000]\tPer Sample Total Time 0.03078\tPer Sample Data Time 0.00198\tPer Sample DNN Time 0.02880\tTrain Loss 0.1288\t\n","Epoch: [2][152/100000]\tPer Sample Total Time 0.02930\tPer Sample Data Time 0.00070\tPer Sample DNN Time 0.02861\tTrain Loss 0.1287\t\n","Epoch: [2][252/100000]\tPer Sample Total Time 0.02898\tPer Sample Data Time 0.00042\tPer Sample DNN Time 0.02855\tTrain Loss 0.1285\t\n","Epoch: [2][352/100000]\tPer Sample Total Time 0.02884\tPer Sample Data Time 0.00031\tPer Sample DNN Time 0.02853\tTrain Loss 0.1285\t\n","Epoch: [2][452/100000]\tPer Sample Total Time 0.02876\tPer Sample Data Time 0.00024\tPer Sample DNN Time 0.02852\tTrain Loss 0.1285\t\n","Epoch: [2][552/100000]\tPer Sample Total Time 0.02872\tPer Sample Data Time 0.00020\tPer Sample DNN Time 0.02852\tTrain Loss 0.1285\t\n","Epoch: [2][652/100000]\tPer Sample Total Time 0.02869\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.02851\tTrain Loss 0.1285\t\n","Epoch: [2][752/100000]\tPer Sample Total Time 0.02866\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.02851\tTrain Loss 0.1284\t\n","Epoch: [2][852/100000]\tPer Sample Total Time 0.02864\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.02851\tTrain Loss 0.1284\t\n","Epoch: [2][952/100000]\tPer Sample Total Time 0.02863\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.02851\tTrain Loss 0.1285\t\n","Epoch: [2][1052/100000]\tPer Sample Total Time 0.02862\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.02851\tTrain Loss 0.1285\t\n","Epoch: [2][1152/100000]\tPer Sample Total Time 0.02861\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.02851\tTrain Loss 0.1285\t\n","Epoch: [2][1252/100000]\tPer Sample Total Time 0.02860\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.02850\tTrain Loss 0.1285\t\n","Epoch: [2][1352/100000]\tPer Sample Total Time 0.02859\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.02850\tTrain Loss 0.1285\t\n","Epoch: [2][1452/100000]\tPer Sample Total Time 0.02858\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.02850\tTrain Loss 0.1285\t\n","Epoch: [2][1552/100000]\tPer Sample Total Time 0.02858\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.02850\tTrain Loss 0.1284\t\n","Epoch: [2][1652/100000]\tPer Sample Total Time 0.02857\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02850\tTrain Loss 0.1284\t\n","Epoch: [2][1752/100000]\tPer Sample Total Time 0.02857\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02850\tTrain Loss 0.1284\t\n","Epoch: [2][1852/100000]\tPer Sample Total Time 0.02857\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02850\tTrain Loss 0.1284\t\n","Epoch: [2][1952/100000]\tPer Sample Total Time 0.02857\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02850\tTrain Loss 0.1284\t\n","Epoch: [2][2052/100000]\tPer Sample Total Time 0.02856\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02850\tTrain Loss 0.1284\t\n","Epoch: [2][2152/100000]\tPer Sample Total Time 0.02856\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02850\tTrain Loss 0.1284\t\n","Epoch: [2][2252/100000]\tPer Sample Total Time 0.02856\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02850\tTrain Loss 0.1284\t\n","Epoch: [2][2352/100000]\tPer Sample Total Time 0.02856\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02850\tTrain Loss 0.1283\t\n","Epoch: [2][2452/100000]\tPer Sample Total Time 0.02856\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.02850\tTrain Loss 0.1283\t\n","Epoch: [2][2552/100000]\tPer Sample Total Time 0.02856\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.02850\tTrain Loss 0.1284\t\n","start validation\n","acc: 0.036569\n","AUC: 0.573994\n","Avg Precision: 0.028571\n","Avg Recall: 1.000000\n","d_prime: 0.263824\n","train_loss: 0.128383\n","valid_loss: 0.128647\n","validation finished\n","Epoch-2 lr: 0.00025\n","epoch 2 training time: 2543.558\n","---------------\n","2023-06-12 14:17:13.188816\n","current #epochs=3, #steps=5296\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][4/100000]\tPer Sample Total Time 0.05042\tPer Sample Data Time 0.02123\tPer Sample DNN Time 0.02919\tTrain Loss 0.1274\t\n","Epoch: [3][104/100000]\tPer Sample Total Time 0.02968\tPer Sample Data Time 0.00102\tPer Sample DNN Time 0.02865\tTrain Loss 0.1282\t\n","Epoch: [3][204/100000]\tPer Sample Total Time 0.02911\tPer Sample Data Time 0.00053\tPer Sample DNN Time 0.02858\tTrain Loss 0.1282\t\n","Epoch: [3][304/100000]\tPer Sample Total Time 0.02893\tPer Sample Data Time 0.00036\tPer Sample DNN Time 0.02857\tTrain Loss 0.1283\t\n","Epoch: [3][404/100000]\tPer Sample Total Time 0.02883\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.02856\tTrain Loss 0.1281\t\n","Epoch: [3][504/100000]\tPer Sample Total Time 0.02877\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.02855\tTrain Loss 0.1281\t\n","Epoch: [3][604/100000]\tPer Sample Total Time 0.02873\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.02855\tTrain Loss 0.1281\t\n","Epoch: [3][704/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.02855\tTrain Loss 0.1280\t\n","Epoch: [3][804/100000]\tPer Sample Total Time 0.02869\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.02855\tTrain Loss 0.1279\t\n","Epoch: [3][904/100000]\tPer Sample Total Time 0.02868\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.02855\tTrain Loss 0.1279\t\n","Epoch: [3][1004/100000]\tPer Sample Total Time 0.02867\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.02855\tTrain Loss 0.1278\t\n","Epoch: [3][1104/100000]\tPer Sample Total Time 0.02866\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.02855\tTrain Loss 0.1278\t\n","Epoch: [3][1204/100000]\tPer Sample Total Time 0.02865\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.02855\tTrain Loss 0.1278\t\n","Epoch: [3][1304/100000]\tPer Sample Total Time 0.02865\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.02855\tTrain Loss 0.1277\t\n","Epoch: [3][1404/100000]\tPer Sample Total Time 0.02864\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.02855\tTrain Loss 0.1277\t\n","Epoch: [3][1504/100000]\tPer Sample Total Time 0.02863\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.02855\tTrain Loss 0.1276\t\n","Epoch: [3][1604/100000]\tPer Sample Total Time 0.02863\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.02855\tTrain Loss 0.1276\t\n","Epoch: [3][1704/100000]\tPer Sample Total Time 0.02862\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02855\tTrain Loss 0.1275\t\n","Epoch: [3][1804/100000]\tPer Sample Total Time 0.02862\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02855\tTrain Loss 0.1274\t\n","Epoch: [3][1904/100000]\tPer Sample Total Time 0.02862\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02855\tTrain Loss 0.1274\t\n","Epoch: [3][2004/100000]\tPer Sample Total Time 0.02861\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02855\tTrain Loss 0.1273\t\n","Epoch: [3][2104/100000]\tPer Sample Total Time 0.02861\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02855\tTrain Loss 0.1272\t\n","Epoch: [3][2204/100000]\tPer Sample Total Time 0.02861\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02855\tTrain Loss 0.1272\t\n","Epoch: [3][2304/100000]\tPer Sample Total Time 0.02861\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02855\tTrain Loss 0.1271\t\n","Epoch: [3][2404/100000]\tPer Sample Total Time 0.02860\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02855\tTrain Loss 0.1271\t\n","Epoch: [3][2504/100000]\tPer Sample Total Time 0.02860\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.02855\tTrain Loss 0.1270\t\n","Epoch: [3][2604/100000]\tPer Sample Total Time 0.02860\tPer Sample Data Time 0.00005\tPer Sample DNN Time 0.02855\tTrain Loss 0.1269\t\n","start validation\n","acc: 0.107404\n","AUC: 0.723510\n","Avg Precision: 0.051583\n","Avg Recall: 0.776202\n","d_prime: 0.839055\n","train_loss: 0.126879\n","valid_loss: 0.119468\n","validation finished\n","Epoch-3 lr: 0.00025\n","epoch 3 training time: 2542.383\n","---------------\n","2023-06-12 14:59:35.572744\n","current #epochs=4, #steps=7944\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][56/100000]\tPer Sample Total Time 0.03084\tPer Sample Data Time 0.00210\tPer Sample DNN Time 0.02874\tTrain Loss 0.1258\t\n","Epoch: [4][156/100000]\tPer Sample Total Time 0.02941\tPer Sample Data Time 0.00077\tPer Sample DNN Time 0.02864\tTrain Loss 0.1253\t\n","Epoch: [4][256/100000]\tPer Sample Total Time 0.02912\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.02865\tTrain Loss 0.1250\t\n","Epoch: [4][356/100000]\tPer Sample Total Time 0.02898\tPer Sample Data Time 0.00035\tPer Sample DNN Time 0.02864\tTrain Loss 0.1247\t\n","Epoch: [4][456/100000]\tPer Sample Total Time 0.02890\tPer Sample Data Time 0.00027\tPer Sample DNN Time 0.02863\tTrain Loss 0.1245\t\n","Epoch: [4][556/100000]\tPer Sample Total Time 0.02886\tPer Sample Data Time 0.00023\tPer Sample DNN Time 0.02863\tTrain Loss 0.1243\t\n","Epoch: [4][656/100000]\tPer Sample Total Time 0.02882\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.02863\tTrain Loss 0.1242\t\n","Epoch: [4][756/100000]\tPer Sample Total Time 0.02880\tPer Sample Data Time 0.00017\tPer Sample DNN Time 0.02863\tTrain Loss 0.1241\t\n","Epoch: [4][856/100000]\tPer Sample Total Time 0.02878\tPer Sample Data Time 0.00015\tPer Sample DNN Time 0.02863\tTrain Loss 0.1240\t\n","Epoch: [4][956/100000]\tPer Sample Total Time 0.02876\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.02863\tTrain Loss 0.1238\t\n","Epoch: [4][1056/100000]\tPer Sample Total Time 0.02875\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.02863\tTrain Loss 0.1237\t\n","Epoch: [4][1156/100000]\tPer Sample Total Time 0.02874\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.02863\tTrain Loss 0.1236\t\n","Epoch: [4][1256/100000]\tPer Sample Total Time 0.02874\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.02863\tTrain Loss 0.1234\t\n","Epoch: [4][1356/100000]\tPer Sample Total Time 0.02873\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.02863\tTrain Loss 0.1233\t\n","Epoch: [4][1456/100000]\tPer Sample Total Time 0.02872\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.02863\tTrain Loss 0.1232\t\n","Epoch: [4][1556/100000]\tPer Sample Total Time 0.02872\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.02863\tTrain Loss 0.1230\t\n","Epoch: [4][1656/100000]\tPer Sample Total Time 0.02872\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.02863\tTrain Loss 0.1229\t\n","Epoch: [4][1756/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.02863\tTrain Loss 0.1227\t\n","Epoch: [4][1856/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.02864\tTrain Loss 0.1226\t\n","Epoch: [4][1956/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02864\tTrain Loss 0.1224\t\n","Epoch: [4][2056/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02864\tTrain Loss 0.1222\t\n","Epoch: [4][2156/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02864\tTrain Loss 0.1220\t\n","Epoch: [4][2256/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02864\tTrain Loss 0.1218\t\n","Epoch: [4][2356/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02865\tTrain Loss 0.1216\t\n","Epoch: [4][2456/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02865\tTrain Loss 0.1215\t\n","Epoch: [4][2556/100000]\tPer Sample Total Time 0.02871\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02865\tTrain Loss 0.1213\t\n","start validation\n","acc: 0.390141\n","AUC: 0.912466\n","Avg Precision: 0.096570\n","Avg Recall: 0.877182\n","d_prime: 1.917815\n","train_loss: 0.121070\n","valid_loss: 0.089193\n","validation finished\n","Epoch-4 lr: 0.00025\n","epoch 4 training time: 2548.409\n","---------------\n","2023-06-12 15:42:03.982222\n","current #epochs=5, #steps=10592\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 32 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(_create_warning_msg(\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [5][8/100000]\tPer Sample Total Time 0.04104\tPer Sample Data Time 0.01199\tPer Sample DNN Time 0.02905\tTrain Loss 0.1166\t\n","Epoch: [5][108/100000]\tPer Sample Total Time 0.02972\tPer Sample Data Time 0.00100\tPer Sample DNN Time 0.02872\tTrain Loss 0.1155\t\n","Epoch: [5][208/100000]\tPer Sample Total Time 0.02925\tPer Sample Data Time 0.00053\tPer Sample DNN Time 0.02872\tTrain Loss 0.1155\t\n","Epoch: [5][308/100000]\tPer Sample Total Time 0.02906\tPer Sample Data Time 0.00036\tPer Sample DNN Time 0.02869\tTrain Loss 0.1152\t\n","Epoch: [5][408/100000]\tPer Sample Total Time 0.02896\tPer Sample Data Time 0.00028\tPer Sample DNN Time 0.02869\tTrain Loss 0.1148\t\n","Epoch: [5][508/100000]\tPer Sample Total Time 0.02891\tPer Sample Data Time 0.00022\tPer Sample DNN Time 0.02868\tTrain Loss 0.1147\t\n","Epoch: [5][608/100000]\tPer Sample Total Time 0.02887\tPer Sample Data Time 0.00019\tPer Sample DNN Time 0.02868\tTrain Loss 0.1144\t\n","Epoch: [5][708/100000]\tPer Sample Total Time 0.02885\tPer Sample Data Time 0.00016\tPer Sample DNN Time 0.02868\tTrain Loss 0.1142\t\n","Epoch: [5][808/100000]\tPer Sample Total Time 0.02882\tPer Sample Data Time 0.00014\tPer Sample DNN Time 0.02868\tTrain Loss 0.1141\t\n","Epoch: [5][908/100000]\tPer Sample Total Time 0.02881\tPer Sample Data Time 0.00013\tPer Sample DNN Time 0.02868\tTrain Loss 0.1139\t\n","Epoch: [5][1008/100000]\tPer Sample Total Time 0.02880\tPer Sample Data Time 0.00012\tPer Sample DNN Time 0.02868\tTrain Loss 0.1137\t\n","Epoch: [5][1108/100000]\tPer Sample Total Time 0.02879\tPer Sample Data Time 0.00011\tPer Sample DNN Time 0.02868\tTrain Loss 0.1135\t\n","Epoch: [5][1208/100000]\tPer Sample Total Time 0.02878\tPer Sample Data Time 0.00010\tPer Sample DNN Time 0.02868\tTrain Loss 0.1134\t\n","Epoch: [5][1308/100000]\tPer Sample Total Time 0.02877\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.02868\tTrain Loss 0.1131\t\n","Epoch: [5][1408/100000]\tPer Sample Total Time 0.02877\tPer Sample Data Time 0.00009\tPer Sample DNN Time 0.02868\tTrain Loss 0.1130\t\n","Epoch: [5][1508/100000]\tPer Sample Total Time 0.02876\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.02868\tTrain Loss 0.1128\t\n","Epoch: [5][1608/100000]\tPer Sample Total Time 0.02876\tPer Sample Data Time 0.00008\tPer Sample DNN Time 0.02868\tTrain Loss 0.1125\t\n","Epoch: [5][1708/100000]\tPer Sample Total Time 0.02875\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02868\tTrain Loss 0.1123\t\n","Epoch: [5][1808/100000]\tPer Sample Total Time 0.02875\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02868\tTrain Loss 0.1121\t\n","Epoch: [5][1908/100000]\tPer Sample Total Time 0.02875\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02868\tTrain Loss 0.1120\t\n","Epoch: [5][2008/100000]\tPer Sample Total Time 0.02875\tPer Sample Data Time 0.00007\tPer Sample DNN Time 0.02868\tTrain Loss 0.1118\t\n","Epoch: [5][2108/100000]\tPer Sample Total Time 0.02875\tPer Sample Data Time 0.00006\tPer Sample DNN Time 0.02868\tTrain Loss 0.1117\t\n"]}],"source":["print('Now starting training for {:d} epochs'.format(args_usepretrain.n_epochs))\n","\n","train(new_audio_model, train_loader, val_loader, args_usepretrain)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1685717381208,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"k89MyoUFlcL1","outputId":"2cca7022-1b33-40b6-9079-4273b91112c9"},"outputs":[{"data":{"text/plain":["torch.Size([1, 6, 768])"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["ast_CIFAR_pretrained.pos_embed.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AXwS3JISUsNb"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"OHa7WkmWHN43"},"source":["## Pretraining QAST on TinyImageNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ywThnaI9LySk"},"outputs":[],"source":["# https://huggingface.co/datasets/Maysee/tiny-imagenet\n","\n","args_pre_tiny_imagenet = Arguments()\n","\n","args_pre_tiny_imagenet.exp_dir = '/content/drive/MyDrive/Thesis/pretrain_qvit_tiny_imagenet'\n","args_pre_tiny_imagenet.n_classes = 200\n","args_pre_tiny_imagenet.img_size = 64\n","\n","\n","args_pre_tiny_imagenet.batch_size = 128\n","args_pre_tiny_imagenet.n_epochs = 20\n","args_pre_tiny_imagenet.lr = 2.5e-5\n","args_pre_tiny_imagenet.warmup = True\n","\n","args_pre_tiny_imagenet.n_print_steps = 100\n","args_pre_tiny_imagenet.num_workers = 8\n","\n","args_pre_tiny_imagenet.wa = False\n","# args_pretraining.lrscheduler_start=0\n","# args_pretraining.lrscheduler_step=1\n","# args_pretraining.lrscheduler_decay=0.85\n","\n","def collate_fn(examples):\n","    images = []\n","    labels = []\n","    convert_tensor = transforms.ToTensor()\n","\n","    for example in examples:\n","        images.append(convert_tensor(example[\"image\"]))\n","        labels.append(example[\"label\"])\n","        \n","    pixel_values = torch.stack(images)\n","    labels = torch.tensor(labels)\n","\n","    b_size = labels.shape[0]\n","    n_classes = args_pre_tiny_imagenet.n_classes\n","    y = torch.zeros(b_size, n_classes)\n","    y[range(y.shape[0]), labels]=1\n","    return (pixel_values, y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-1eVx5oOwfY"},"outputs":[],"source":["access_token = \"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\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["c8ea121a133940f4a2eafcffeb49cc18","2b058987dd8248a0960c7335c3b1863c","eb0640ae585f4750ad9bc33336bdfac9","1ad7cc0a8d0a4c36ae8fd749ffdfb7df","e67bc67451c04ed1833c6095c316520e","99dd2b4409514e3dac999dd7839314ad","6bf59483d619464084e0f6ffce5215e9","60e4e797065f4abb95febd17c13d09d3","a07229eb24784422abca39e03adbd474","9a699e045e304beab82614cd726ab44d","9b99dcf547b1412db444fe780a40ded5","b46487a437974435838aed2a0b72b837","43b796e103b74a56aaacf3c38e84ee65","77f8be7594cf4f9687f9212008f36947","84733200abf347dfbd720c7ea2472305","c3b9857691a94f62b17f0f3208fbde00","303fa1bc1f8e4e1b8eff31e959eceb0f","dfbb8845cba94c19b57c1ec561bfe3c0","46e8d0ac293441b48459ff5b9752af67","a8367883b5544c6cb944d073cb0f1d38","1ecfb8df6a2444869bbc10d6b5811c27","8184cf4b6bbf46f1bc1dad90ade9d15a"]},"executionInfo":{"elapsed":2523,"status":"ok","timestamp":1685968851112,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"fUC6-MdBHTtN","outputId":"506fac79-62d1-4306-d2cc-7ae56ec7288b"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8ea121a133940f4a2eafcffeb49cc18","version_major":2,"version_minor":0},"text/plain":["Downloading metadata:   0%|          | 0.00/3.52k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b46487a437974435838aed2a0b72b837","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/3.90k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset, Image\n","dset = load_dataset('Maysee/tiny-imagenet', split='train', streaming=True, use_auth_token=access_token).cast_column(\"image\", Image())\n","dset_eval = load_dataset('Maysee/tiny-imagenet', split='valid', streaming=True, use_auth_token=access_token).cast_column(\"image\", Image())\n","# dset_test = load_dataset('Maysee/tiny-imagenet', split='test', streaming=True, use_auth_token=access_token).cast_column(\"image\", Image())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9oORdusjJcwu"},"outputs":[],"source":["dset = dset.map(transforms_, batched=True)\n","dset_eval = dset_eval.map(transforms_, batched=True)\n","# dset_test = dset_test.map(transforms_, batched=True)\n","\n","dset_iter = dset.with_format(\"torch\")\n","dset_eval_iter = dset_eval.with_format(\"torch\")\n","# dset_test_iter = dset_test.with_format(\"torch\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yAB_QA5-JnPz"},"outputs":[],"source":["train_loader_tiny_imagenet = DataLoader(dset_iter, collate_fn=collate_fn, batch_size = args_pre_tiny_imagenet.batch_size, pin_memory=True)\n","eval_loader_tiny_imagenet = DataLoader(dset_eval_iter, collate_fn=collate_fn, batch_size=args_pre_tiny_imagenet.batch_size, pin_memory=True)\n","# test_loader_tiny_imagenet = DataLoader(dset_test_iter, collate_fn=collate_fn, batch_size=args_pre_tiny_imagenet.batch_size, pin_memory=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mMBEcFCTMn_2"},"outputs":[],"source":["ast_tiny_imagenet = QVIT(label_dim=args_pre_tiny_imagenet.n_classes, img_size = args_pre_tiny_imagenet.img_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4765,"status":"ok","timestamp":1685968876043,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"m8hWIRqoNkPB","outputId":"8535d195-bbe8-416e-d5d1-9b1fdde449c3"},"outputs":[{"data":{"text/plain":["QVIT(\n","  (patch_embed): PatchEmbedding(\n","    (proj): Conv2d(4, 768, kernel_size=(16, 16), stride=(16, 16))\n","    (norm): Identity()\n","  )\n","  (pos_drop): Dropout(p=0.0, inplace=False)\n","  (blocks): Sequential(\n","    (0): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1057)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=40)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=501)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=899)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (1): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1219)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=905)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=473)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=49)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (2): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=200)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=152)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=352)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=675)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (3): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=634)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=511)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=458)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=347)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (4): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=471)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1091)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=742)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=715)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (5): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=468)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=471)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=424)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=712)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (6): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=711)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=322)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=807)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=947)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (7): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=802)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=885)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=632)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=90)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (8): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=901)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=370)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=318)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=403)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (9): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=119)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1194)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=141)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=309)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (10): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=200)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=491)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=1106)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=921)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","    (11): Block(\n","      (norm1): Norm()\n","      (attn): Attention(\n","        (qkv): QuaternionLinearAutograd(in_features=192, out_features=576, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=717)\n","        (q_norm): Identity()\n","        (k_norm): Identity()\n","        (attn_drop): Dropout(p=0.0, inplace=False)\n","        (proj): QuaternionLinearAutograd(in_features=192, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=408)\n","        (proj_drop): Dropout(p=0.1, inplace=False)\n","      )\n","      (norm2): Norm()\n","      (mlp): Mlp(\n","        (fc1): QuaternionLinearAutograd(in_features=192, out_features=768, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=615)\n","        (drop1): Dropout(p=0.1, inplace=False)\n","        (fc2): QuaternionLinearAutograd(in_features=768, out_features=192, bias=True, init_criterion=glorot, weight_init=quaternion, rotation=False, seed=369)\n","        (drop2): Dropout(p=0.1, inplace=False)\n","      )\n","    )\n","  )\n","  (norm): Norm()\n","  (fc_norm): Norm()\n","  (head): Linear(in_features=768, out_features=200, bias=True)\n",")"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["ast_tiny_imagenet.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1342,"status":"ok","timestamp":1685968881093,"user":{"displayName":"Bota D","userId":"04482539542256056244"},"user_tz":-120},"id":"MnUewVwaNptw","outputId":"cb4181ad-8d1f-418c-be1c-5120fa2cc399"},"outputs":[{"name":"stdout","output_type":"stream","text":["Folders already exists\n","Target.csv already exists\n"]}],"source":["prepare_result_saving(args_pre_tiny_imagenet, val_data = eval_loader_tiny_imagenet)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"vnalWliXOFga","outputId":"ed60aa2e-eae0-4e2c-f02e-8e2afbc72bfd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Now starting training for 20 epochs\n","running on cuda\n","Total parameter number is : 22.283 million\n","Total trainable parameter number is : 22.283 million\n","now training with speechcommands, main metrics: acc, loss function: BCEWithLogitsLoss(), learning rate scheduler: <torch.optim.lr_scheduler.MultiStepLR object at 0x7f4b584f30a0>\n","The learning rate scheduler starts at 5 epoch with decay rate of 0.850 every 1 epochs\n","current #steps=0, #epochs=1\n","start training...\n","---------------\n","2023-06-05 12:41:20.555890\n","current #epochs=1, #steps=0\n","warm-up learning rate is 0.000000\n","warm-up learning rate is 0.000001\n","warm-up learning rate is 0.000003\n","Epoch: [1][100/100000]\tPer Sample Total Time 0.00372\tPer Sample Data Time 0.00090\tPer Sample DNN Time 0.00282\tTrain Loss 0.6722\t\n","warm-up learning rate is 0.000004\n","warm-up learning rate is 0.000005\n","Epoch: [1][200/100000]\tPer Sample Total Time 0.00328\tPer Sample Data Time 0.00075\tPer Sample DNN Time 0.00253\tTrain Loss 0.6047\t\n","warm-up learning rate is 0.000006\n","warm-up learning rate is 0.000008\n","Epoch: [1][300/100000]\tPer Sample Total Time 0.00315\tPer Sample Data Time 0.00069\tPer Sample DNN Time 0.00246\tTrain Loss 0.5536\t\n","warm-up learning rate is 0.000009\n","warm-up learning rate is 0.000010\n","Epoch: [1][400/100000]\tPer Sample Total Time 0.00313\tPer Sample Data Time 0.00070\tPer Sample DNN Time 0.00243\tTrain Loss 0.5102\t\n","warm-up learning rate is 0.000011\n","warm-up learning rate is 0.000013\n","Epoch: [1][500/100000]\tPer Sample Total Time 0.00309\tPer Sample Data Time 0.00068\tPer Sample DNN Time 0.00241\tTrain Loss 0.4686\t\n","warm-up learning rate is 0.000014\n","warm-up learning rate is 0.000015\n","Epoch: [1][600/100000]\tPer Sample Total Time 0.00305\tPer Sample Data Time 0.00065\tPer Sample DNN Time 0.00240\tTrain Loss 0.4286\t\n","warm-up learning rate is 0.000016\n","warm-up learning rate is 0.000017\n","Epoch: [1][700/100000]\tPer Sample Total Time 0.00303\tPer Sample Data Time 0.00064\tPer Sample DNN Time 0.00239\tTrain Loss 0.3914\t\n","warm-up learning rate is 0.000019\n","start validation\n","acc: 0.005000\n","AUC: 0.487289\n","Avg Precision: 0.005000\n","Avg Recall: 1.000000\n","d_prime: -0.045067\n","train_loss: 0.364322\n","valid_loss: 0.111425\n","validation finished\n","Epoch-1 lr: 1.8750000000000002e-05\n","epoch 1 training time: 331.672\n","---------------\n","2023-06-05 12:46:52.229230\n","current #epochs=2, #steps=782\n","warm-up learning rate is 0.000020\n","Epoch: [2][18/100000]\tPer Sample Total Time 0.00382\tPer Sample Data Time 0.00132\tPer Sample DNN Time 0.00250\tTrain Loss 0.1094\t\n","warm-up learning rate is 0.000021\n","warm-up learning rate is 0.000023\n","Epoch: [2][118/100000]\tPer Sample Total Time 0.00299\tPer Sample Data Time 0.00061\tPer Sample DNN Time 0.00238\tTrain Loss 0.0963\t\n","warm-up learning rate is 0.000024\n","start validation\n","acc: 0.005000\n","AUC: 0.492146\n","Avg Precision: 0.005000\n","Avg Recall: 1.000000\n","d_prime: -0.027844\n","train_loss: 0.086028\n","valid_loss: 0.065761\n","warm-up learning rate is 0.000025\n","Epoch: [2][218/100000]\tPer Sample Total Time 0.00375\tPer Sample Data Time 0.00140\tPer Sample DNN Time 0.00235\tTrain Loss 0.0859\t\n","Epoch: [2][318/100000]\tPer Sample Total Time 0.00345\tPer Sample Data Time 0.00112\tPer Sample DNN Time 0.00233\tTrain Loss 0.0779\t\n","Epoch: [2][418/100000]\tPer Sample Total Time 0.00327\tPer Sample Data Time 0.00096\tPer Sample DNN Time 0.00231\tTrain Loss 0.0719\t\n","Epoch: [2][518/100000]\tPer Sample Total Time 0.00316\tPer Sample Data Time 0.00087\tPer Sample DNN Time 0.00230\tTrain Loss 0.0672\t\n","Epoch: [2][618/100000]\tPer Sample Total Time 0.00309\tPer Sample Data Time 0.00080\tPer Sample DNN Time 0.00229\tTrain Loss 0.0634\t\n","Epoch: [2][718/100000]\tPer Sample Total Time 0.00304\tPer Sample Data Time 0.00076\tPer Sample DNN Time 0.00228\tTrain Loss 0.0604\t\n","start validation\n","acc: 0.004900\n","AUC: 0.502861\n","Avg Precision: 0.005000\n","Avg Recall: 1.000000\n","d_prime: 0.010142\n","train_loss: 0.058759\n","valid_loss: 0.038877\n","validation finished\n","Epoch-2 lr: 2.5e-05\n","epoch 2 training time: 325.000\n","---------------\n","2023-06-05 12:52:17.229339\n","current #epochs=3, #steps=1564\n","Epoch: [3][36/100000]\tPer Sample Total Time 0.00294\tPer Sample Data Time 0.00060\tPer Sample DNN Time 0.00233\tTrain Loss 0.0393\t\n","Epoch: [3][136/100000]\tPer Sample Total Time 0.00281\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.00233\tTrain Loss 0.0386\t\n","Epoch: [3][236/100000]\tPer Sample Total Time 0.00281\tPer Sample Data Time 0.00049\tPer Sample DNN Time 0.00232\tTrain Loss 0.0380\t\n","Epoch: [3][336/100000]\tPer Sample Total Time 0.00280\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.00232\tTrain Loss 0.0375\t\n","start validation\n","acc: 0.004800\n","AUC: 0.508815\n","Avg Precision: 0.005000\n","Avg Recall: 1.000000\n","d_prime: 0.031251\n","train_loss: 0.037107\n","valid_loss: 0.034749\n","Epoch: [3][436/100000]\tPer Sample Total Time 0.00320\tPer Sample Data Time 0.00088\tPer Sample DNN Time 0.00232\tTrain Loss 0.0371\t\n","Epoch: [3][536/100000]\tPer Sample Total Time 0.00311\tPer Sample Data Time 0.00080\tPer Sample DNN Time 0.00231\tTrain Loss 0.0367\t\n","Epoch: [3][636/100000]\tPer Sample Total Time 0.00305\tPer Sample Data Time 0.00075\tPer Sample DNN Time 0.00230\tTrain Loss 0.0364\t\n","Epoch: [3][736/100000]\tPer Sample Total Time 0.00300\tPer Sample Data Time 0.00071\tPer Sample DNN Time 0.00229\tTrain Loss 0.0361\t\n","start validation\n","acc: 0.005000\n","AUC: 0.517032\n","Avg Precision: 0.005000\n","Avg Recall: 1.000000\n","d_prime: 0.060395\n","train_loss: 0.036026\n","valid_loss: 0.033355\n","validation finished\n","Epoch-3 lr: 2.5e-05\n","epoch 3 training time: 323.040\n","---------------\n","2023-06-05 12:57:40.269880\n","current #epochs=4, #steps=2346\n","Epoch: [4][54/100000]\tPer Sample Total Time 0.00294\tPer Sample Data Time 0.00061\tPer Sample DNN Time 0.00233\tTrain Loss 0.0339\t\n","Epoch: [4][154/100000]\tPer Sample Total Time 0.00281\tPer Sample Data Time 0.00050\tPer Sample DNN Time 0.00231\tTrain Loss 0.0338\t\n","Epoch: [4][254/100000]\tPer Sample Total Time 0.00280\tPer Sample Data Time 0.00050\tPer Sample DNN Time 0.00231\tTrain Loss 0.0337\t\n","Epoch: [4][354/100000]\tPer Sample Total Time 0.00279\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.00231\tTrain Loss 0.0336\t\n","Epoch: [4][454/100000]\tPer Sample Total Time 0.00278\tPer Sample Data Time 0.00047\tPer Sample DNN Time 0.00231\tTrain Loss 0.0336\t\n","Epoch: [4][554/100000]\tPer Sample Total Time 0.00279\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.00231\tTrain Loss 0.0335\t\n","start validation\n","acc: 0.005000\n","AUC: 0.522431\n","Avg Precision: 0.005000\n","Avg Recall: 1.000000\n","d_prime: 0.079559\n","train_loss: 0.033451\n","valid_loss: 0.032195\n","Epoch: [4][654/100000]\tPer Sample Total Time 0.00307\tPer Sample Data Time 0.00075\tPer Sample DNN Time 0.00231\tTrain Loss 0.0335\t\n","Epoch: [4][754/100000]\tPer Sample Total Time 0.00301\tPer Sample Data Time 0.00071\tPer Sample DNN Time 0.00230\tTrain Loss 0.0334\t\n","start validation\n","acc: 0.005000\n","AUC: 0.527890\n","Avg Precision: 0.005000\n","Avg Recall: 1.000000\n","d_prime: 0.098947\n","train_loss: 0.033385\n","valid_loss: 0.032115\n","validation finished\n","Epoch-4 lr: 2.5e-05\n","epoch 4 training time: 324.646\n","---------------\n","2023-06-05 13:03:04.915710\n","current #epochs=5, #steps=3128\n","Epoch: [5][72/100000]\tPer Sample Total Time 0.00281\tPer Sample Data Time 0.00051\tPer Sample DNN Time 0.00229\tTrain Loss 0.0330\t\n","Epoch: [5][172/100000]\tPer Sample Total Time 0.00281\tPer Sample Data Time 0.00051\tPer Sample DNN Time 0.00229\tTrain Loss 0.0330\t\n","Epoch: [5][272/100000]\tPer Sample Total Time 0.00278\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.00229\tTrain Loss 0.0329\t\n","Epoch: [5][372/100000]\tPer Sample Total Time 0.00277\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.00230\tTrain Loss 0.0330\t\n","Epoch: [5][472/100000]\tPer Sample Total Time 0.00278\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.00230\tTrain Loss 0.0330\t\n","Epoch: [5][572/100000]\tPer Sample Total Time 0.00277\tPer Sample Data Time 0.00048\tPer Sample DNN Time 0.00230\tTrain Loss 0.0330\t\n","Epoch: [5][672/100000]\tPer Sample Total Time 0.00277\tPer Sample Data Time 0.00047\tPer Sample DNN Time 0.00230\tTrain Loss 0.0330\t\n","Epoch: [5][772/100000]\tPer Sample Total Time 0.00277\tPer Sample Data Time 0.00046\tPer Sample DNN Time 0.00230\tTrain Loss 0.0330\t\n","start validation\n","acc: 0.005000\n","AUC: 0.534442\n","Avg Precision: 0.005000\n","Avg Recall: 1.000000\n","d_prime: 0.122247\n","train_loss: 0.032982\n","valid_loss: 0.031760\n","validation finished\n","Epoch-5 lr: 2.125e-05\n","epoch 5 training time: 301.603\n","---------------\n","2023-06-05 13:08:06.518564\n","current #epochs=6, #steps=3910\n","start validation\n","acc: 0.005000\n","AUC: 0.538212\n","Avg Precision: 0.005000\n","Avg Recall: 1.000000\n","d_prime: 0.135664\n","train_loss: 0.032974\n","valid_loss: 0.031667\n","Epoch: [6][90/100000]\tPer Sample Total Time 0.00495\tPer Sample Data Time 0.00263\tPer Sample DNN Time 0.00232\tTrain Loss 0.0330\t\n","Epoch: [6][190/100000]\tPer Sample Total Time 0.00375\tPer Sample Data Time 0.00149\tPer Sample DNN Time 0.00226\tTrain Loss 0.0329\t\n"]}],"source":["print('Now starting training for {:d} epochs'.format(args_pre_tiny_imagenet.n_epochs))\n","\n","train(ast_tiny_imagenet, train_loader_tiny_imagenet, eval_loader_tiny_imagenet, args_pre_tiny_imagenet)"]},{"cell_type":"markdown","metadata":{"id":"56I9T9FQKIUc"},"source":["## ImageNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9Sl--mWiKKWr"},"outputs":[],"source":["from datasets import load_dataset, Image\n","dset = load_dataset('imagenet-1k', split='train', streaming=True, use_auth_token=True).cast_column(\"image\", Image())\n","dset_eval = load_dataset('imagenet-1k', split='validation', streaming=True, use_auth_token=True).cast_column(\"image\", Image())\n","dset_test = load_dataset('imagenet-1k', split='test', streaming=True, use_auth_token=True).cast_column(\"image\", Image())\n","\n","dset = dset.map(transforms_, batched=True)\n","dset_eval = dset_eval.map(transforms_, batched=True)\n","dset_test = dset_test.map(transforms_, batched=True)\n","\n","dset_iter = dset.with_format(\"torch\")\n","dset_eval_iter = dset_eval.with_format(\"torch\")\n","dset_test_iter = dset_test.with_format(\"torch\")\n","\n","train_loader_imagenet = DataLoader(dset_iter, collate_fn=collate_fn, batch_size = args_pretraining.batch_size, pin_memory=True)\n","eval_loader_imagenet = DataLoader(dset_eval_iter, collate_fn=collate_fn, batch_size=args_pretraining.batch_size, pin_memory=True)\n","test_loader_imagenet = DataLoader(dset_test_iter, collate_fn=collate_fn, batch_size=args_pretraining.batch_size, pin_memory=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WvzPlQI-Lt69"},"outputs":[],"source":["ast_tiny_imagenet = QVIT(label_dim=args_pretraining.n_classes, img_size = 32)"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","toc_visible":true,"provenance":[],"gpuClass":"premium"},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"1ad7cc0a8d0a4c36ae8fd749ffdfb7df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9a699e045e304beab82614cd726ab44d","placeholder":"​","style":"IPY_MODEL_9b99dcf547b1412db444fe780a40ded5","value":" 3.52k/3.52k [00:00&lt;00:00, 236kB/s]"}},"1ecfb8df6a2444869bbc10d6b5811c27":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b058987dd8248a0960c7335c3b1863c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99dd2b4409514e3dac999dd7839314ad","placeholder":"​","style":"IPY_MODEL_6bf59483d619464084e0f6ffce5215e9","value":"Downloading metadata: 100%"}},"303fa1bc1f8e4e1b8eff31e959eceb0f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"43b796e103b74a56aaacf3c38e84ee65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_303fa1bc1f8e4e1b8eff31e959eceb0f","placeholder":"​","style":"IPY_MODEL_dfbb8845cba94c19b57c1ec561bfe3c0","value":"Downloading readme: 100%"}},"46e8d0ac293441b48459ff5b9752af67":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60e4e797065f4abb95febd17c13d09d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bf59483d619464084e0f6ffce5215e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77f8be7594cf4f9687f9212008f36947":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_46e8d0ac293441b48459ff5b9752af67","max":3900,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a8367883b5544c6cb944d073cb0f1d38","value":3900}},"8184cf4b6bbf46f1bc1dad90ade9d15a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"84733200abf347dfbd720c7ea2472305":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ecfb8df6a2444869bbc10d6b5811c27","placeholder":"​","style":"IPY_MODEL_8184cf4b6bbf46f1bc1dad90ade9d15a","value":" 3.90k/3.90k [00:00&lt;00:00, 247kB/s]"}},"99dd2b4409514e3dac999dd7839314ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a699e045e304beab82614cd726ab44d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b99dcf547b1412db444fe780a40ded5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a07229eb24784422abca39e03adbd474":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8367883b5544c6cb944d073cb0f1d38":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b46487a437974435838aed2a0b72b837":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_43b796e103b74a56aaacf3c38e84ee65","IPY_MODEL_77f8be7594cf4f9687f9212008f36947","IPY_MODEL_84733200abf347dfbd720c7ea2472305"],"layout":"IPY_MODEL_c3b9857691a94f62b17f0f3208fbde00"}},"c3b9857691a94f62b17f0f3208fbde00":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8ea121a133940f4a2eafcffeb49cc18":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b058987dd8248a0960c7335c3b1863c","IPY_MODEL_eb0640ae585f4750ad9bc33336bdfac9","IPY_MODEL_1ad7cc0a8d0a4c36ae8fd749ffdfb7df"],"layout":"IPY_MODEL_e67bc67451c04ed1833c6095c316520e"}},"dfbb8845cba94c19b57c1ec561bfe3c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e67bc67451c04ed1833c6095c316520e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb0640ae585f4750ad9bc33336bdfac9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_60e4e797065f4abb95febd17c13d09d3","max":3522,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a07229eb24784422abca39e03adbd474","value":3522}}}}},"nbformat":4,"nbformat_minor":0}